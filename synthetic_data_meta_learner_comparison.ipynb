{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to import duecredit due to No module named 'duecredit'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from causalml.inference.meta import BaseXRegressor, BaseRRegressor, BaseSRegressor, BaseTRegressor, BaseDRRegressor\n",
    "from causalml.inference.tree import CausalRandomForestRegressor\n",
    "from causalml.metrics import get_cumgain, auuc_score, plot_gain\n",
    "from causalml.dataset import synthetic_data\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression, Lasso\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.utils.extmath import cartesian\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.base import clone\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "palette = ['plum', 'g', 'orange', 'r', 'b', 'yellow', 'cyan', 'white']\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import norm, uniform\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.special import softmax as scipy_softmax\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from causalml.inference.meta.base import BaseLearner\n",
    "from causalml.inference.meta.utils import (\n",
    "    check_treatment_vector,\n",
    "    check_p_conditions,\n",
    "    convert_pd_to_np,\n",
    ")\n",
    "from causalml.metrics import regression_metrics\n",
    "from causalml.propensity import compute_propensity_score\n",
    "\n",
    "logger = logging.getLogger(\"causalml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseRTLearner(BaseLearner):\n",
    "    \"\"\"A parent class for H-learner regressor classes.\n",
    "\n",
    "    A H-learner estimates treatment effects with three machine learning models.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        learner=None,\n",
    "        outcome_learner=None,\n",
    "        control_effect_learner=None,\n",
    "        treatment_effect_learner=None,\n",
    "        ate_alpha=0.05,\n",
    "        control_name=0,\n",
    "    ):\n",
    "        \"\"\"Initialize a H-learner.\n",
    "\n",
    "        Args:\n",
    "            learner (optional): a model to estimate outcomes and treatment effects in both the control and treatment\n",
    "                groups\n",
    "            outcome_learner (optional): a model to estimate outcomes\n",
    "            control_effect_learner (optional): a model to estimate treatment effects in the control group\n",
    "            treatment_effect_learner (optional): a model to estimate treatment effects in the treatment group\n",
    "            ate_alpha (float, optional): the confidence level alpha of the ATE estimate\n",
    "            control_name (str or int, optional): name of control group\n",
    "        \"\"\"\n",
    "        assert (learner is not None) or (\n",
    "            (outcome_learner is not None)\n",
    "            and (control_effect_learner is not None)\n",
    "            and (treatment_effect_learner is not None)\n",
    "        )\n",
    "\n",
    "        if outcome_learner is None:\n",
    "            self.model_mu = deepcopy(learner)\n",
    "        else:\n",
    "            self.model_mu = outcome_learner\n",
    "\n",
    "        if control_effect_learner is None:\n",
    "            self.model_tau_c = deepcopy(learner)\n",
    "        else:\n",
    "            self.model_tau_c = control_effect_learner\n",
    "\n",
    "        if treatment_effect_learner is None:\n",
    "            self.model_tau_t = deepcopy(learner)\n",
    "        else:\n",
    "            self.model_tau_t = treatment_effect_learner\n",
    "\n",
    "        self.ate_alpha = ate_alpha\n",
    "        self.control_name = control_name\n",
    "\n",
    "        self.propensity = None\n",
    "        self.propensity_model = None\n",
    "        self.model_p = LogisticRegression()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            \"{}(outcome_learner={},\\n\"\n",
    "            \"\\tcontrol_effect_learner={},\\n\"\n",
    "            \"\\ttreatment_effect_learner={})\".format(\n",
    "                self.__class__.__name__,\n",
    "                self.model_mu.__repr__(),\n",
    "                self.model_tau_c.__repr__(),\n",
    "                self.model_tau_t.__repr__(),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def fit(self, X, treatment, y, p=None):\n",
    "        \"\"\"Fit the inference model.\n",
    "\n",
    "        Args:\n",
    "            X (np.matrix or np.array or pd.Dataframe): a feature matrix\n",
    "            treatment (np.array or pd.Series): a treatment vector\n",
    "            y (np.array or pd.Series): an outcome vector\n",
    "            p (np.ndarray or pd.Series or dict, optional): an array of propensity scores of float (0,1) in the\n",
    "                single-treatment case; or, a dictionary of treatment groups that map to propensity vectors of\n",
    "                float (0,1); if None will run ElasticNetPropensityModel() to generate the propensity scores.\n",
    "        \"\"\"\n",
    "        X, treatment, y = convert_pd_to_np(X, treatment, y)\n",
    "        check_treatment_vector(treatment, self.control_name)\n",
    "        self.t_groups = np.unique(treatment[treatment != self.control_name])\n",
    "        self.t_groups.sort()\n",
    "\n",
    "        if p is None:\n",
    "            self._set_propensity_models(X=X, treatment=treatment, y=y)\n",
    "            p = self.propensity\n",
    "        else:\n",
    "            p = self._format_p(p, self.t_groups)\n",
    "\n",
    "        self._classes = {group: i for i, group in enumerate(self.t_groups)}\n",
    "        self.models_tau_c = {\n",
    "            group: deepcopy(self.model_tau_c) for group in self.t_groups\n",
    "        }\n",
    "        self.models_tau_t = {\n",
    "            group: deepcopy(self.model_tau_t) for group in self.t_groups\n",
    "        }\n",
    "\n",
    "        self.vars_c = {}\n",
    "        self.vars_t = {}\n",
    "\n",
    "        # Train outcome model\n",
    "        self.model_mu.fit(X, y)\n",
    "\n",
    "        for group in self.t_groups:\n",
    "            mask = (treatment == group) | (treatment == self.control_name)\n",
    "            treatment_filt = treatment[mask]\n",
    "            X_filt = X[mask]\n",
    "            y_filt = y[mask]\n",
    "            w = (treatment_filt == group).astype(int)\n",
    "\n",
    "            # Calculate variances and treatment effects\n",
    "            var_c = (\n",
    "                y_filt[w == 0] - self.model_mu.predict(X_filt[w == 0])\n",
    "            ).var()\n",
    "            self.vars_c[group] = var_c\n",
    "            var_t = (\n",
    "                y_filt[w == 1] - self.model_mu.predict(X_filt[w == 1])\n",
    "            ).var()\n",
    "            self.vars_t[group] = var_t\n",
    "\n",
    "            # Train treatment models\n",
    "            d_c = (self.model_mu.predict(X_filt[w == 0]) - y_filt[w == 0])\n",
    "            d_t = (y_filt[w == 1] - self.model_mu.predict(X_filt[w == 1]))\n",
    "            self.models_tau_c[group].fit(X_filt[w == 0], d_c)\n",
    "            self.models_tau_t[group].fit(X_filt[w == 1], d_t)\n",
    "\n",
    "    def predict(\n",
    "        self, X, treatment=None, y=None, p=None, return_components=False, verbose=True\n",
    "    ):\n",
    "        \"\"\"Predict treatment effects.\n",
    "\n",
    "        Args:\n",
    "            X (np.matrix or np.array or pd.Dataframe): a feature matrix\n",
    "            treatment (np.array or pd.Series, optional): a treatment vector\n",
    "            y (np.array or pd.Series, optional): an outcome vector\n",
    "            p (np.ndarray or pd.Series or dict, optional): an array of propensity scores of float (0,1) in the\n",
    "                single-treatment case; or, a dictionary of treatment groups that map to propensity vectors of\n",
    "                float (0,1); if None will run ElasticNetPropensityModel() to generate the propensity scores.\n",
    "            return_components (bool, optional): whether to return differences for treatment and control seperately\n",
    "            verbose (bool, optional): whether to output progress logs\n",
    "        Returns:\n",
    "            (numpy.ndarray): Predictions of treatment effects.\n",
    "        \"\"\"\n",
    "        X, treatment, y = convert_pd_to_np(X, treatment, y)\n",
    "\n",
    "        if p is None:\n",
    "            logger.info(\"Generating propensity score\")\n",
    "            p = dict()\n",
    "            for group in self.t_groups:\n",
    "                p_model = self.propensity_model[group]\n",
    "                p[group] = p_model.predict(X)\n",
    "        else:\n",
    "            p = self._format_p(p, self.t_groups)\n",
    "\n",
    "        te = np.zeros((X.shape[0], self.t_groups.shape[0]))\n",
    "        dhat_cs = {}\n",
    "        dhat_ts = {}\n",
    "\n",
    "        for i, group in enumerate(self.t_groups):\n",
    "            model_tau_c = self.models_tau_c[group]\n",
    "            model_tau_t = self.models_tau_t[group]\n",
    "            dhat_cs[group] = model_tau_c.predict(X)\n",
    "            dhat_ts[group] = model_tau_t.predict(X)\n",
    "\n",
    "            _te = (dhat_cs[group] + dhat_ts[group]).reshape(\n",
    "                -1, 1\n",
    "            )\n",
    "            te[:, i] = np.ravel(_te)\n",
    "\n",
    "            if (y is not None) and (treatment is not None) and verbose:\n",
    "                mask = (treatment == group) | (treatment == self.control_name)\n",
    "                treatment_filt = treatment[mask]\n",
    "                X_filt = X[mask]\n",
    "                y_filt = y[mask]\n",
    "                w = (treatment_filt == group).astype(int)\n",
    "\n",
    "                yhat = np.zeros_like(y, dtype=float)\n",
    "                yhat = self.model_mu.predict(X)\n",
    "\n",
    "                logger.info(\"Error metrics for group {}\".format(group))\n",
    "                regression_metrics(y, yhat, w)\n",
    "\n",
    "        if not return_components:\n",
    "            return te\n",
    "        else:\n",
    "            return te, dhat_cs, dhat_ts\n",
    "\n",
    "    def fit_predict(\n",
    "        self,\n",
    "        X,\n",
    "        treatment,\n",
    "        y,\n",
    "        p=None,\n",
    "        return_ci=False,\n",
    "        n_bootstraps=1000,\n",
    "        bootstrap_size=10000,\n",
    "        return_components=False,\n",
    "        verbose=True,\n",
    "    ):\n",
    "        \"\"\"Fit the treatment effect and outcome models of the R learner and predict treatment effects.\n",
    "\n",
    "        Args:\n",
    "            X (np.matrix or np.array or pd.Dataframe): a feature matrix\n",
    "            treatment (np.array or pd.Series): a treatment vector\n",
    "            y (np.array or pd.Series): an outcome vector\n",
    "            p (np.ndarray or pd.Series or dict, optional): an array of propensity scores of float (0,1) in the\n",
    "                single-treatment case; or, a dictionary of treatment groups that map to propensity vectors of\n",
    "                float (0,1); if None will run ElasticNetPropensityModel() to generate the propensity scores.\n",
    "            return_ci (bool): whether to return confidence intervals\n",
    "            n_bootstraps (int): number of bootstrap iterations\n",
    "            bootstrap_size (int): number of samples per bootstrap\n",
    "            return_components (bool, optional): whether to return outcome for treatment and control seperately\n",
    "            verbose (str): whether to output progress logs\n",
    "        Returns:\n",
    "            (numpy.ndarray): Predictions of treatment effects. Output dim: [n_samples, n_treatment]\n",
    "                If return_ci, returns CATE [n_samples, n_treatment], LB [n_samples, n_treatment],\n",
    "                UB [n_samples, n_treatment]\n",
    "        \"\"\"\n",
    "        X, treatment, y = convert_pd_to_np(X, treatment, y)\n",
    "        self.fit(X, treatment, y, p)\n",
    "\n",
    "        if p is None:\n",
    "            p = self.propensity\n",
    "        else:\n",
    "            p = self._format_p(p, self.t_groups)\n",
    "\n",
    "        te = self.predict(\n",
    "            X, treatment=treatment, y=y, p=p, return_components=return_components\n",
    "        )\n",
    "\n",
    "        if not return_ci:\n",
    "            return te\n",
    "        else:\n",
    "            t_groups_global = self.t_groups\n",
    "            _classes_global = self._classes\n",
    "            model_mu_global = deepcopy(self.model_mu)\n",
    "            models_tau_c_global = deepcopy(self.models_tau_c)\n",
    "            models_tau_t_global = deepcopy(self.models_tau_t)\n",
    "            te_bootstraps = np.zeros(\n",
    "                shape=(X.shape[0], self.t_groups.shape[0], n_bootstraps)\n",
    "            )\n",
    "\n",
    "            logger.info(\"Bootstrap Confidence Intervals\")\n",
    "            for i in tqdm(range(n_bootstraps)):\n",
    "                te_b = self.bootstrap(X, treatment, y, p, size=bootstrap_size)\n",
    "                te_bootstraps[:, :, i] = te_b\n",
    "\n",
    "            te_lower = np.percentile(te_bootstraps, (self.ate_alpha / 2) * 100, axis=2)\n",
    "            te_upper = np.percentile(\n",
    "                te_bootstraps, (1 - self.ate_alpha / 2) * 100, axis=2\n",
    "            )\n",
    "\n",
    "            # set member variables back to global (currently last bootstrapped outcome)\n",
    "            self.t_groups = t_groups_global\n",
    "            self._classes = _classes_global\n",
    "            self.model_mu = deepcopy(model_mu_global)\n",
    "            self.models_tau_c = deepcopy(models_tau_c_global)\n",
    "            self.models_tau_t = deepcopy(models_tau_t_global)\n",
    "\n",
    "            return (te, te_lower, te_upper)\n",
    "\n",
    "    def estimate_ate(\n",
    "        self,\n",
    "        X,\n",
    "        treatment,\n",
    "        y,\n",
    "        p=None,\n",
    "        bootstrap_ci=False,\n",
    "        n_bootstraps=1000,\n",
    "        bootstrap_size=10000,\n",
    "        pretrain=False,\n",
    "    ):\n",
    "        \"\"\"Estimate the Average Treatment Effect (ATE).\n",
    "\n",
    "        Args:\n",
    "            X (np.matrix or np.array or pd.Dataframe): a feature matrix\n",
    "            treatment (np.array or pd.Series): a treatment vector\n",
    "            y (np.array or pd.Series): an outcome vector\n",
    "            p (np.ndarray or pd.Series or dict, optional): an array of propensity scores of float (0,1) in the\n",
    "                single-treatment case; or, a dictionary of treatment groups that map to propensity vectors of\n",
    "                float (0,1); if None will run ElasticNetPropensityModel() to generate the propensity scores.\n",
    "            bootstrap_ci (bool): whether run bootstrap for confidence intervals\n",
    "            n_bootstraps (int): number of bootstrap iterations\n",
    "            bootstrap_size (int): number of samples per bootstrap\n",
    "            pretrain (bool): whether a model has been fit, default False.\n",
    "        Returns:\n",
    "            The mean and confidence interval (LB, UB) of the ATE estimate.\n",
    "        \"\"\"\n",
    "        if pretrain:\n",
    "            if p is None:\n",
    "                # when p is null, use pretrain propensity score\n",
    "                if not self.propensity:\n",
    "                    raise ValueError(\"no propensity score, please call fit() first\")\n",
    "                te, dhat_cs, dhat_ts = self.predict(\n",
    "                    X, treatment, y, p=self.propensity, return_components=True\n",
    "                )\n",
    "            else:\n",
    "                p = self._format_p(p, self.t_groups)\n",
    "                te, dhat_cs, dhat_ts = self.predict(\n",
    "                    X, treatment, y, p=p, return_components=True\n",
    "                )\n",
    "        else:\n",
    "            te, dhat_cs, dhat_ts = self.fit_predict(\n",
    "                X, treatment, y, p, return_components=True\n",
    "            )\n",
    "        X, treatment, y = convert_pd_to_np(X, treatment, y)\n",
    "\n",
    "        if p is None:\n",
    "            p = self.propensity\n",
    "        else:\n",
    "            p = self._format_p(p, self.t_groups)\n",
    "\n",
    "        ate = np.zeros(self.t_groups.shape[0])\n",
    "        ate_lb = np.zeros(self.t_groups.shape[0])\n",
    "        ate_ub = np.zeros(self.t_groups.shape[0])\n",
    "\n",
    "        for i, group in enumerate(self.t_groups):\n",
    "            _ate = te[:, i].mean()\n",
    "\n",
    "            mask = (treatment == group) | (treatment == self.control_name)\n",
    "            treatment_filt = treatment[mask]\n",
    "            w = (treatment_filt == group).astype(int)\n",
    "            prob_treatment = float(sum(w)) / w.shape[0]\n",
    "\n",
    "            dhat_c = dhat_cs[group][mask]\n",
    "            dhat_t = dhat_ts[group][mask]\n",
    "            p_filt = p[group][mask]\n",
    "\n",
    "            # SE formula is based on the lower bound formula (7) from Imbens, Guido W., and Jeffrey M. Wooldridge. 2009.\n",
    "            # \"Recent Developments in the Econometrics of Program Evaluation.\" Journal of Economic Literature\n",
    "            se = np.sqrt(\n",
    "                (\n",
    "                    self.vars_t[group] / prob_treatment\n",
    "                    + self.vars_c[group] / (1 - prob_treatment)\n",
    "                    + (p_filt * dhat_c + (1 - p_filt) * dhat_t).var()\n",
    "                )\n",
    "                / w.shape[0]\n",
    "            )\n",
    "\n",
    "            _ate_lb = _ate - se * norm.ppf(1 - self.ate_alpha / 2)\n",
    "            _ate_ub = _ate + se * norm.ppf(1 - self.ate_alpha / 2)\n",
    "\n",
    "            ate[i] = _ate\n",
    "            ate_lb[i] = _ate_lb\n",
    "            ate_ub[i] = _ate_ub\n",
    "\n",
    "        if not bootstrap_ci:\n",
    "            return ate, ate_lb, ate_ub\n",
    "        else:\n",
    "            t_groups_global = self.t_groups\n",
    "            _classes_global = self._classes\n",
    "            model_mu_global = deepcopy(self.model_mu)\n",
    "            models_tau_c_global = deepcopy(self.models_tau_c)\n",
    "            models_tau_t_global = deepcopy(self.models_tau_t)\n",
    "\n",
    "            logger.info(\"Bootstrap Confidence Intervals for ATE\")\n",
    "            ate_bootstraps = np.zeros(shape=(self.t_groups.shape[0], n_bootstraps))\n",
    "\n",
    "            for n in tqdm(range(n_bootstraps)):\n",
    "                cate_b = self.bootstrap(X, treatment, y, p, size=bootstrap_size)\n",
    "                ate_bootstraps[:, n] = cate_b.mean()\n",
    "\n",
    "            ate_lower = np.percentile(\n",
    "                ate_bootstraps, (self.ate_alpha / 2) * 100, axis=1\n",
    "            )\n",
    "            ate_upper = np.percentile(\n",
    "                ate_bootstraps, (1 - self.ate_alpha / 2) * 100, axis=1\n",
    "            )\n",
    "\n",
    "            # set member variables back to global (currently last bootstrapped outcome)\n",
    "            self.t_groups = t_groups_global\n",
    "            self._classes = _classes_global\n",
    "            self.model_mu = deepcopy(model_mu_global)\n",
    "            self.models_tau_c = deepcopy(models_tau_c_global)\n",
    "            self.models_tau_t = deepcopy(models_tau_t_global)\n",
    "            return ate, ate_lower, ate_upper\n",
    "\n",
    "class BaseRTRegressor(BaseRTLearner):\n",
    "    \"\"\"\n",
    "    A parent class for H-learner regressor classes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        learner=None,\n",
    "        outcome_learner=None,\n",
    "        control_effect_learner=None,\n",
    "        treatment_effect_learner=None,\n",
    "        ate_alpha=0.05,\n",
    "        control_name=0,\n",
    "    ):\n",
    "        \"\"\"Initialize an X-learner regressor.\n",
    "\n",
    "        Args:\n",
    "            learner (optional): a model to estimate outcomes and treatment effects in both the control and treatment\n",
    "                groups\n",
    "            outcome_learner (optional): a model to estimate outcomes\n",
    "            control_effect_learner (optional): a model to estimate treatment effects in the control group\n",
    "            treatment_effect_learner (optional): a model to estimate treatment effects in the treatment group\n",
    "            ate_alpha (float, optional): the confidence level alpha of the ATE estimate\n",
    "            control_name (str or int, optional): name of control group\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            learner=learner,\n",
    "            outcome_learner=outcome_learner,\n",
    "            control_effect_learner=control_effect_learner,\n",
    "            treatment_effect_learner=treatment_effect_learner,\n",
    "            ate_alpha=ate_alpha,\n",
    "            control_name=control_name,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasePLearner(BaseLearner):\n",
    "    \"\"\"A parent class for P-learner regressor classes.\n",
    "\n",
    "    A P-learner estimates treatment effects with one machine learning model.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        learner=None,\n",
    "        ate_alpha=0.05,\n",
    "        control_name=0,\n",
    "    ):\n",
    "        \"\"\"Initialize a P-learner.\n",
    "\n",
    "        Args:\n",
    "            learner (optional): a model to estimate outcomes and treatment effects in both the control and treatment\n",
    "                groups\n",
    "            outcome_learner (optional): a model to estimate outcomes\n",
    "            control_effect_learner (optional): a model to estimate treatment effects in the control group\n",
    "            treatment_effect_learner (optional): a model to estimate treatment effects in the treatment group\n",
    "            ate_alpha (float, optional): the confidence level alpha of the ATE estimate\n",
    "            control_name (str or int, optional): name of control group\n",
    "        \"\"\"\n",
    "        assert (learner is not None)\n",
    "\n",
    "        self.model_nu = deepcopy(learner)\n",
    "\n",
    "        self.ate_alpha = ate_alpha\n",
    "        self.control_name = control_name\n",
    "\n",
    "        self.propensity = None\n",
    "        self.propensity_model = None\n",
    "        self.model_p = LogisticRegression()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            \"{}(pairwise_learner={})\".format(\n",
    "                self.__class__.__name__,\n",
    "                self.model_nu.__repr__(),\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def pair_data(self, X, treatment, y, num_samples):\n",
    "\n",
    "        # Split T=0 and T=1\n",
    "        X0 = X[treatment == 0]\n",
    "        Y0 = y[treatment == 0]\n",
    "        X1 = X[treatment == 1]\n",
    "        Y1 = y[treatment == 1]\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "        X1_scaled = scaler.fit_transform(X1)\n",
    "        X0_scaled = scaler.fit_transform(X0)\n",
    "\n",
    "        # Build KD-tree from Y\n",
    "        tree = cKDTree(X1_scaled)\n",
    "\n",
    "        # Query for k nearest neighbours\n",
    "        distances, indices = tree.query(X0_scaled, k=num_samples)\n",
    "        # Randomly sample rows from X_treated for each row in X_control\n",
    "        random_indices = np.random.randint(0, len(X1), (len(X0), num_samples))\n",
    "        \n",
    "        # Expand T=0 data to match shape\n",
    "        X0_expanded = np.repeat(X0, num_samples, axis=0)  # Repeat X0\n",
    "        Y0_expanded = np.repeat(Y0, num_samples, axis=0)  # Repeat Y0\n",
    "\n",
    "        # Get corresponding T=1 data (using the random indices)\n",
    "        X1_sampled = X1[indices.flatten()]\n",
    "        Y1_sampled = Y1[indices.flatten()]\n",
    "\n",
    "        # Reshape the sampled X1 and Y1 for the final DataFrame\n",
    "        X1_sampled = X1_sampled.reshape(-1, X.shape[1])\n",
    "        Y1_sampled = Y1_sampled.reshape(-1, 1)\n",
    "\n",
    "        # Combine the matrices (X0 with X1, Y0 with Y1)\n",
    "        X_combined = np.concatenate([X0_expanded, X1_sampled], axis=1)  # Concatenate feature matrices\n",
    "        Y_combined = np.column_stack((Y0_expanded, Y1_sampled))  # Concatenate outcome matrices\n",
    "\n",
    "        # Calculate outcome differences\n",
    "        nu = Y_combined[:,1] - Y_combined[:,0]\n",
    "\n",
    "        return X_combined, nu\n",
    "\n",
    "    def fit(self, X, treatment, y, p, num_samples=3):\n",
    "        \"\"\"Fit the inference model.\n",
    "\n",
    "        Args:\n",
    "            X (np.matrix or np.array or pd.Dataframe): a feature matrix\n",
    "            treatment (np.array or pd.Series): a treatment vector\n",
    "            y (np.array or pd.Series): an outcome vector\n",
    "            p (np.ndarray or pd.Series or dict, optional): an array of propensity scores of float (0,1) in the\n",
    "                single-treatment case; or, a dictionary of treatment groups that map to propensity vectors of\n",
    "                float (0,1); if None will run ElasticNetPropensityModel() to generate the propensity scores.\n",
    "            num_samples (optional): number of treated samples to pair with each control.\n",
    "        \"\"\"\n",
    "        \n",
    "        X, y = convert_pd_to_np(X, y)\n",
    "        X_pair, nu = self.pair_data(X, treatment, y, num_samples)\n",
    "\n",
    "        self.t_groups = np.unique(treatment[treatment != self.control_name])\n",
    "        self.t_groups.sort()\n",
    "\n",
    "        self._classes = {group: i for i, group in enumerate(self.t_groups)}\n",
    "\n",
    "        self.vars_c = {}\n",
    "        self.vars_t = {}\n",
    "\n",
    "        # Train outcome model\n",
    "        self.model_nu.fit(X_pair, nu)\n",
    "\n",
    "        # for group in self.t_groups:\n",
    "        #     mask = (treatment == group) | (treatment == self.control_name)\n",
    "        #     treatment_filt = treatment[mask]\n",
    "        #     X_filt = X[mask]\n",
    "        #     y_filt = y[mask]\n",
    "        #     w = (treatment_filt == group).astype(int)\n",
    "\n",
    "        #     # Calculate variances and treatment effects\n",
    "        #     var_c = (\n",
    "        #         y_filt[w == 0] - self.model_mu.predict(X_filt[w == 0])\n",
    "        #     ).var()\n",
    "        #     self.vars_c[group] = var_c\n",
    "        #     var_t = (\n",
    "        #         y_filt[w == 1] - self.model_mu.predict(X_filt[w == 1])\n",
    "        #     ).var()\n",
    "        #     self.vars_t[group] = var_t\n",
    "\n",
    "        #     # Train treatment models\n",
    "        #     d_c = (self.model_mu.predict(X_filt[w == 0]) - y_filt[w == 0])\n",
    "        #     d_t = (y_filt[w == 1] - self.model_mu.predict(X_filt[w == 1]))\n",
    "        #     self.models_tau_c[group].fit(X_filt[w == 0], d_c)\n",
    "        #     self.models_tau_t[group].fit(X_filt[w == 1], d_t)\n",
    "\n",
    "    def predict(\n",
    "        self, X, treatment=None, y=None, p=None, return_components=False, verbose=True\n",
    "    ):\n",
    "        \"\"\"Predict treatment effects.\n",
    "\n",
    "        Args:\n",
    "            X (np.matrix or np.array or pd.Dataframe): a feature matrix\n",
    "            treatment (np.array or pd.Series, optional): a treatment vector\n",
    "            y (np.array or pd.Series, optional): an outcome vector\n",
    "            p (np.ndarray or pd.Series or dict, optional): an array of propensity scores of float (0,1) in the\n",
    "                single-treatment case; or, a dictionary of treatment groups that map to propensity vectors of\n",
    "                float (0,1); if None will run ElasticNetPropensityModel() to generate the propensity scores.\n",
    "            return_components (bool, optional): whether to return differences for treatment and control seperately\n",
    "            verbose (bool, optional): whether to output progress logs\n",
    "        Returns:\n",
    "            (numpy.ndarray): Predictions of treatment effects.\n",
    "        \"\"\"\n",
    "\n",
    "        X, treatment, y = convert_pd_to_np(X, treatment, y)\n",
    "        X = np.concatenate([X, X], axis=1)\n",
    "\n",
    "        # if p is None:\n",
    "        #     logger.info(\"Generating propensity score\")\n",
    "        #     p = dict()\n",
    "        #     for group in self.t_groups:\n",
    "        #         p_model = self.propensity_model[group]\n",
    "        #         p[group] = p_model.predict(X)\n",
    "        # else:\n",
    "        #     p = self._format_p(p, self.t_groups)\n",
    "\n",
    "        te = np.zeros((X.shape[0], self.t_groups.shape[0]))\n",
    "        dhat_cs = {}\n",
    "        dhat_ts = {}\n",
    "\n",
    "        _te = (self.model_nu.predict(X)).reshape(\n",
    "            -1, 1\n",
    "        )\n",
    "        te[:, 0] = np.ravel(_te)\n",
    "\n",
    "        # for i, group in enumerate(self.t_groups):\n",
    "        #     model_tau_c = self.models_tau_c[group]\n",
    "        #     model_tau_t = self.models_tau_t[group]\n",
    "        #     dhat_cs[group] = model_tau_c.predict(X)\n",
    "        #     dhat_ts[group] = model_tau_t.predict(X)\n",
    "\n",
    "        #     _te = (dhat_cs[group] + dhat_ts[group]).reshape(\n",
    "        #         -1, 1\n",
    "        #     )\n",
    "        #     te[:, i] = np.ravel(_te)\n",
    "\n",
    "        #     if (y is not None) and (treatment is not None) and verbose:\n",
    "        #         mask = (treatment == group) | (treatment == self.control_name)\n",
    "        #         treatment_filt = treatment[mask]\n",
    "        #         X_filt = X[mask]\n",
    "        #         y_filt = y[mask]\n",
    "        #         w = (treatment_filt == group).astype(int)\n",
    "\n",
    "        #         yhat = np.zeros_like(y, dtype=float)\n",
    "        #         yhat = self.model_mu.predict(X)\n",
    "\n",
    "        #         logger.info(\"Error metrics for group {}\".format(group))\n",
    "        #         regression_metrics(y, yhat, w)\n",
    "\n",
    "        if not return_components:\n",
    "            return te\n",
    "        else:\n",
    "            return te, dhat_cs, dhat_ts\n",
    "\n",
    "    def fit_predict(\n",
    "        self,\n",
    "        X,\n",
    "        treatment,\n",
    "        y,\n",
    "        p=None,\n",
    "        num_samples=3,\n",
    "        return_ci=False,\n",
    "        n_bootstraps=1000,\n",
    "        bootstrap_size=10000,\n",
    "        return_components=False,\n",
    "        verbose=True,\n",
    "    ):\n",
    "        \"\"\"Fit the treatment effect and outcome models of the R learner and predict treatment effects.\n",
    "\n",
    "        Args:\n",
    "            X (np.matrix or np.array or pd.Dataframe): a feature matrix\n",
    "            treatment (np.array or pd.Series): a treatment vector\n",
    "            y (np.array or pd.Series): an outcome vector\n",
    "            p (np.ndarray or pd.Series or dict, optional): an array of propensity scores of float (0,1) in the\n",
    "                single-treatment case; or, a dictionary of treatment groups that map to propensity vectors of\n",
    "                float (0,1); if None will run ElasticNetPropensityModel() to generate the propensity scores.\n",
    "            return_ci (bool): whether to return confidence intervals\n",
    "            n_bootstraps (int): number of bootstrap iterations\n",
    "            bootstrap_size (int): number of samples per bootstrap\n",
    "            return_components (bool, optional): whether to return outcome for treatment and control seperately\n",
    "            verbose (str): whether to output progress logs\n",
    "        Returns:\n",
    "            (numpy.ndarray): Predictions of treatment effects. Output dim: [n_samples, n_treatment]\n",
    "                If return_ci, returns CATE [n_samples, n_treatment], LB [n_samples, n_treatment],\n",
    "                UB [n_samples, n_treatment]\n",
    "        \"\"\"\n",
    "        X, treatment, y = convert_pd_to_np(X, treatment, y)\n",
    "        self.fit(X, treatment, y, p, num_samples)\n",
    "\n",
    "        if p is None:\n",
    "            p = self.propensity\n",
    "        else:\n",
    "            p = self._format_p(p, self.t_groups)\n",
    "\n",
    "        te = self.predict(\n",
    "            X, treatment=treatment, y=y, p=p, return_components=return_components\n",
    "        )\n",
    "\n",
    "        if not return_ci:\n",
    "            return te\n",
    "        else:\n",
    "            t_groups_global = self.t_groups\n",
    "            _classes_global = self._classes\n",
    "            model_nu_global = deepcopy(self.model_nu)\n",
    "            te_bootstraps = np.zeros(\n",
    "                shape=(X.shape[0], self.t_groups.shape[0], n_bootstraps)\n",
    "            )\n",
    "\n",
    "            logger.info(\"Bootstrap Confidence Intervals\")\n",
    "            for i in tqdm(range(n_bootstraps)):\n",
    "                te_b = self.bootstrap(X, treatment, y, p, size=bootstrap_size)\n",
    "                te_bootstraps[:, :, i] = te_b\n",
    "\n",
    "            te_lower = np.percentile(te_bootstraps, (self.ate_alpha / 2) * 100, axis=2)\n",
    "            te_upper = np.percentile(\n",
    "                te_bootstraps, (1 - self.ate_alpha / 2) * 100, axis=2\n",
    "            )\n",
    "\n",
    "            # set member variables back to global (currently last bootstrapped outcome)\n",
    "            self.t_groups = t_groups_global\n",
    "            self._classes = _classes_global\n",
    "            self.model_nu = deepcopy(model_nu_global)\n",
    "\n",
    "            return (te, te_lower, te_upper)\n",
    "\n",
    "    def estimate_ate(\n",
    "        self,\n",
    "        X,\n",
    "        treatment,\n",
    "        y,\n",
    "        p=None,\n",
    "        bootstrap_ci=False,\n",
    "        n_bootstraps=1000,\n",
    "        bootstrap_size=10000,\n",
    "        pretrain=False,\n",
    "    ):\n",
    "        \"\"\"Estimate the Average Treatment Effect (ATE).\n",
    "\n",
    "        Args:\n",
    "            X (np.matrix or np.array or pd.Dataframe): a feature matrix\n",
    "            treatment (np.array or pd.Series): a treatment vector\n",
    "            y (np.array or pd.Series): an outcome vector\n",
    "            p (np.ndarray or pd.Series or dict, optional): an array of propensity scores of float (0,1) in the\n",
    "                single-treatment case; or, a dictionary of treatment groups that map to propensity vectors of\n",
    "                float (0,1); if None will run ElasticNetPropensityModel() to generate the propensity scores.\n",
    "            bootstrap_ci (bool): whether run bootstrap for confidence intervals\n",
    "            n_bootstraps (int): number of bootstrap iterations\n",
    "            bootstrap_size (int): number of samples per bootstrap\n",
    "            pretrain (bool): whether a model has been fit, default False.\n",
    "        Returns:\n",
    "            The mean and confidence interval (LB, UB) of the ATE estimate.\n",
    "        \"\"\"\n",
    "        if pretrain:\n",
    "            if p is None:\n",
    "                # when p is null, use pretrain propensity score\n",
    "                if not self.propensity:\n",
    "                    raise ValueError(\"no propensity score, please call fit() first\")\n",
    "                te, dhat_cs, dhat_ts = self.predict(\n",
    "                    X, treatment, y, p=self.propensity, return_components=True\n",
    "                )\n",
    "            else:\n",
    "                p = self._format_p(p, self.t_groups)\n",
    "                te, dhat_cs, dhat_ts = self.predict(\n",
    "                    X, treatment, y, p=p, return_components=True\n",
    "                )\n",
    "        else:\n",
    "            te, dhat_cs, dhat_ts = self.fit_predict(\n",
    "                X, treatment, y, p, return_components=True\n",
    "            )\n",
    "        X, treatment, y = convert_pd_to_np(X, treatment, y)\n",
    "\n",
    "        if p is None:\n",
    "            p = self.propensity\n",
    "        else:\n",
    "            p = self._format_p(p, self.t_groups)\n",
    "\n",
    "        ate = np.zeros(self.t_groups.shape[0])\n",
    "        ate_lb = np.zeros(self.t_groups.shape[0])\n",
    "        ate_ub = np.zeros(self.t_groups.shape[0])\n",
    "\n",
    "        ate[0] = te[:, 0].mean()\n",
    "\n",
    "        # for i, group in enumerate(self.t_groups):\n",
    "        #     _ate = te[:, i].mean()\n",
    "\n",
    "        #     mask = (treatment == group) | (treatment == self.control_name)\n",
    "        #     treatment_filt = treatment[mask]\n",
    "        #     w = (treatment_filt == group).astype(int)\n",
    "        #     prob_treatment = float(sum(w)) / w.shape[0]\n",
    "\n",
    "        #     dhat_c = dhat_cs[group][mask]\n",
    "        #     dhat_t = dhat_ts[group][mask]\n",
    "        #     p_filt = p[group][mask]\n",
    "\n",
    "        #     # SE formula is based on the lower bound formula (7) from Imbens, Guido W., and Jeffrey M. Wooldridge. 2009.\n",
    "        #     # \"Recent Developments in the Econometrics of Program Evaluation.\" Journal of Economic Literature\n",
    "        #     se = np.sqrt(\n",
    "        #         (\n",
    "        #             self.vars_t[group] / prob_treatment\n",
    "        #             + self.vars_c[group] / (1 - prob_treatment)\n",
    "        #             + (p_filt * dhat_c + (1 - p_filt) * dhat_t).var()\n",
    "        #         )\n",
    "        #         / w.shape[0]\n",
    "        #     )\n",
    "\n",
    "        #     _ate_lb = _ate - se * norm.ppf(1 - self.ate_alpha / 2)\n",
    "        #     _ate_ub = _ate + se * norm.ppf(1 - self.ate_alpha / 2)\n",
    "\n",
    "        #     ate[i] = _ate\n",
    "        #     ate_lb[i] = _ate_lb\n",
    "        #     ate_ub[i] = _ate_ub\n",
    "\n",
    "        if not bootstrap_ci:\n",
    "            return ate, ate_lb, ate_ub\n",
    "        else:\n",
    "            t_groups_global = self.t_groups\n",
    "            _classes_global = self._classes\n",
    "            model_nu_global = deepcopy(self.model_nu)\n",
    "\n",
    "            logger.info(\"Bootstrap Confidence Intervals for ATE\")\n",
    "            ate_bootstraps = np.zeros(shape=(self.t_groups.shape[0], n_bootstraps))\n",
    "\n",
    "            for n in tqdm(range(n_bootstraps)):\n",
    "                cate_b = self.bootstrap(X, treatment, y, p, size=bootstrap_size)\n",
    "                ate_bootstraps[:, n] = cate_b.mean()\n",
    "\n",
    "            ate_lower = np.percentile(\n",
    "                ate_bootstraps, (self.ate_alpha / 2) * 100, axis=1\n",
    "            )\n",
    "            ate_upper = np.percentile(\n",
    "                ate_bootstraps, (1 - self.ate_alpha / 2) * 100, axis=1\n",
    "            )\n",
    "\n",
    "            # set member variables back to global (currently last bootstrapped outcome)\n",
    "            self.t_groups = t_groups_global\n",
    "            self._classes = _classes_global\n",
    "            self.model_nu = deepcopy(model_nu_global)\n",
    "            return ate, ate_lower, ate_upper\n",
    "\n",
    "class BasePRegressor(BasePLearner):\n",
    "    \"\"\"\n",
    "    A parent class for P-learner regressor classes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        learner=None,\n",
    "        ate_alpha=0.05,\n",
    "        control_name=0,\n",
    "    ):\n",
    "        \"\"\"Initialize a P-learner regressor.\n",
    "\n",
    "        Args:\n",
    "            learner (optional): a model to estimate outcomes and treatment effects in both the control and treatment\n",
    "                groups\n",
    "            ate_alpha (float, optional): the confidence level alpha of the ATE estimate\n",
    "            control_name (str or int, optional): name of control group\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            learner=learner,\n",
    "            ate_alpha=ate_alpha,\n",
    "            control_name=control_name,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseRPLearner(BaseLearner):\n",
    "    \"\"\"A parent class for PH-learner regressor classes.\n",
    "\n",
    "    A PH-learner estimates treatment effects with two machine learning models.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        learner=None,\n",
    "        outcome_learner=None,\n",
    "        pair_learner=None,\n",
    "        ate_alpha=0.05,\n",
    "        control_name=0,\n",
    "    ):\n",
    "        \"\"\"Initialize a H-learner.\n",
    "\n",
    "        Args:\n",
    "            learner (optional): a model to estimate outcomes and treatment effects in both the control and treatment\n",
    "                groups\n",
    "            outcome_learner (optional): a model to estimate outcomes\n",
    "            pair_learner (optional): a model to estimate pair outcome differences\n",
    "            treatment_effect_learner (optional): a model to estimate treatment effects in the treatment group\n",
    "            ate_alpha (float, optional): the confidence level alpha of the ATE estimate\n",
    "            control_name (str or int, optional): name of control group\n",
    "        \"\"\"\n",
    "        assert (learner is not None) or (\n",
    "            (outcome_learner is not None)\n",
    "            and (pair_learner is not None)\n",
    "        )\n",
    "\n",
    "        if outcome_learner is None:\n",
    "            self.model_mu = deepcopy(learner)\n",
    "        else:\n",
    "            self.model_mu = outcome_learner\n",
    "\n",
    "        if pair_learner is None:\n",
    "            self.model_nu = deepcopy(learner)\n",
    "        else:\n",
    "            self.model_nu = pair_learner\n",
    "\n",
    "        self.ate_alpha = ate_alpha\n",
    "        self.control_name = control_name\n",
    "\n",
    "        self.propensity = None\n",
    "        self.propensity_model = None\n",
    "        self.model_p = LogisticRegression()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            \"{}(outcome_learner={},\\n\"\n",
    "            \"\\tpair_learner={})\".format(\n",
    "                self.__class__.__name__,\n",
    "                self.model_mu.__repr__(),\n",
    "                self.model_nu.__repr__()\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def pair_data(self, X, treatment, y, num_samples):\n",
    "\n",
    "        # Split T=0 and T=1\n",
    "        X0 = X[treatment == 0]\n",
    "        Y0 = y[treatment == 0]\n",
    "        X1 = X[treatment == 1]\n",
    "        Y1 = y[treatment == 1]\n",
    "\n",
    "        scaler = MinMaxScaler()\n",
    "        X1_scaled = scaler.fit_transform(X1)\n",
    "        X0_scaled = scaler.fit_transform(X0)\n",
    "\n",
    "        # Build KD-tree from Y\n",
    "        tree = cKDTree(X1_scaled)\n",
    "\n",
    "        # Query for k nearest neighbours\n",
    "        distances, indices = tree.query(X0_scaled, k=num_samples)\n",
    "        # Randomly sample rows from X_treated for each row in X_control\n",
    "        random_indices = np.random.randint(0, len(X1), (len(X0), num_samples))\n",
    "\n",
    "        # Expand T=0 data to match shape\n",
    "        X0_expanded = np.repeat(X0, num_samples, axis=0)  # Repeat X0 for 5 times\n",
    "        Y0_expanded = np.repeat(Y0, num_samples, axis=0)  # Repeat Y0 for 5 times\n",
    "\n",
    "        # Get corresponding T=1 data (using the random indices)\n",
    "        X1_sampled = X1[indices.flatten()]\n",
    "        Y1_sampled = Y1[indices.flatten()]\n",
    "\n",
    "        # Reshape the sampled X1 and Y1 for the final DataFrame\n",
    "        X1_sampled = X1_sampled.reshape(-1, X.shape[1])\n",
    "        Y1_sampled = Y1_sampled.reshape(-1, 1)\n",
    "\n",
    "        # Combine the matrices (X0 with X1, Y0 with Y1)\n",
    "        X_combined = np.concatenate([X0_expanded, X1_sampled], axis=1)  # Concatenate feature matrices\n",
    "        Y_combined = np.column_stack((Y0_expanded, Y1_sampled))  # Concatenate outcome matrices\n",
    "\n",
    "        # Calculate outcome differences\n",
    "        nu = Y_combined[:,1] - self.model_mu.predict(X1_sampled) + self.model_mu.predict(X0_expanded) - Y_combined[:,0]\n",
    "\n",
    "        return X_combined, nu\n",
    "\n",
    "    def fit(self, X, treatment, y, p=None, num_samples=5):\n",
    "        \"\"\"Fit the inference model.\n",
    "\n",
    "        Args:\n",
    "            X (np.matrix or np.array or pd.Dataframe): a feature matrix\n",
    "            treatment (np.array or pd.Series): a treatment vector\n",
    "            y (np.array or pd.Series): an outcome vector\n",
    "            p (np.ndarray or pd.Series or dict, optional): an array of propensity scores of float (0,1) in the\n",
    "                single-treatment case; or, a dictionary of treatment groups that map to propensity vectors of\n",
    "                float (0,1); if None will run ElasticNetPropensityModel() to generate the propensity scores.\n",
    "            num_samples (int, optional): number of pairs for each control observation\n",
    "        \"\"\"\n",
    "        X, treatment, y = convert_pd_to_np(X, treatment, y)\n",
    "        check_treatment_vector(treatment, self.control_name)\n",
    "\n",
    "        self.t_groups = np.unique(treatment[treatment != self.control_name])\n",
    "        self.t_groups.sort()\n",
    "\n",
    "        self._classes = {group: i for i, group in enumerate(self.t_groups)}\n",
    "\n",
    "        # if p is None:\n",
    "        #     self._set_propensity_models(X=X, treatment=treatment, y=y)\n",
    "        #     p = self.propensity\n",
    "        # else:\n",
    "        #     p = self._format_p(p, self.t_groups)\n",
    "\n",
    "        self.vars_c = {}\n",
    "        self.vars_t = {}\n",
    "\n",
    "        # Train outcome model\n",
    "        self.model_mu.fit(X, y)\n",
    "\n",
    "        # Train pair model\n",
    "        X_paired, nu = self.pair_data(X, treatment, y, num_samples)\n",
    "        self.model_nu.fit(X_paired, nu)\n",
    "\n",
    "    def predict(\n",
    "        self, X, treatment=None, y=None, p=None, return_components=False, verbose=True\n",
    "    ):\n",
    "        \"\"\"Predict treatment effects.\n",
    "\n",
    "        Args:\n",
    "            X (np.matrix or np.array or pd.Dataframe): a feature matrix\n",
    "            treatment (np.array or pd.Series, optional): a treatment vector\n",
    "            y (np.array or pd.Series, optional): an outcome vector\n",
    "            p (np.ndarray or pd.Series or dict, optional): an array of propensity scores of float (0,1) in the\n",
    "                single-treatment case; or, a dictionary of treatment groups that map to propensity vectors of\n",
    "                float (0,1); if None will run ElasticNetPropensityModel() to generate the propensity scores.\n",
    "            return_components (bool, optional): whether to return differences for treatment and control seperately\n",
    "            verbose (bool, optional): whether to output progress logs\n",
    "        Returns:\n",
    "            (numpy.ndarray): Predictions of treatment effects.\n",
    "        \"\"\"\n",
    "        X= convert_pd_to_np(X)\n",
    "        X_paired = np.concatenate([X, X], axis=1)\n",
    "\n",
    "        # if p is None:\n",
    "        #     logger.info(\"Generating propensity score\")\n",
    "        #     p = dict()\n",
    "        #     for group in self.t_groups:\n",
    "        #         p_model = self.propensity_model[group]\n",
    "        #         p[group] = p_model.predict(X)\n",
    "        # else:\n",
    "        #     p = self._format_p(p, self.t_groups)\n",
    "\n",
    "        te = np.zeros((X.shape[0], self.t_groups.shape[0]))\n",
    "\n",
    "        fhat = self.model_mu.predict(X)\n",
    "        tauhat = self.model_nu.predict(X_paired)\n",
    "\n",
    "        _te = (tauhat).reshape(\n",
    "            -1, 1\n",
    "        )\n",
    "        te[:, 0] = np.ravel(_te)\n",
    "\n",
    "        if not return_components:\n",
    "            return te\n",
    "        else:\n",
    "            return te, fhat\n",
    "\n",
    "    def fit_predict(\n",
    "        self,\n",
    "        X,\n",
    "        treatment,\n",
    "        y,\n",
    "        p=None,\n",
    "        num_samples=5,\n",
    "        return_ci=False,\n",
    "        n_bootstraps=1000,\n",
    "        bootstrap_size=10000,\n",
    "        return_components=False,\n",
    "        verbose=True,\n",
    "    ):\n",
    "        \"\"\"Fit the treatment effect and outcome models of the R learner and predict treatment effects.\n",
    "\n",
    "        Args:\n",
    "            X (np.matrix or np.array or pd.Dataframe): a feature matrix\n",
    "            treatment (np.array or pd.Series): a treatment vector\n",
    "            y (np.array or pd.Series): an outcome vector\n",
    "            p (np.ndarray or pd.Series or dict, optional): an array of propensity scores of float (0,1) in the\n",
    "                single-treatment case; or, a dictionary of treatment groups that map to propensity vectors of\n",
    "                float (0,1); if None will run ElasticNetPropensityModel() to generate the propensity scores.\n",
    "            num_samples (int): number of pairs for each control observation\n",
    "            return_ci (bool): whether to return confidence intervals\n",
    "            n_bootstraps (int): number of bootstrap iterations\n",
    "            bootstrap_size (int): number of samples per bootstrap\n",
    "            return_components (bool, optional): whether to return outcome for treatment and control seperately\n",
    "            verbose (str): whether to output progress logs\n",
    "        Returns:\n",
    "            (numpy.ndarray): Predictions of treatment effects. Output dim: [n_samples, n_treatment]\n",
    "                If return_ci, returns CATE [n_samples, n_treatment], LB [n_samples, n_treatment],\n",
    "                UB [n_samples, n_treatment]\n",
    "        \"\"\"\n",
    "        X, treatment, y = convert_pd_to_np(X, treatment, y)\n",
    "        self.fit(X, treatment, y, p, num_samples)\n",
    "\n",
    "        # if p is None:\n",
    "        #     p = self.propensity\n",
    "        # else:\n",
    "        #     p = self._format_p(p, self.t_groups)\n",
    "\n",
    "        te = self.predict(\n",
    "            X, return_components=return_components\n",
    "        )\n",
    "\n",
    "        if not return_ci:\n",
    "            return te\n",
    "        else:\n",
    "            t_groups_global = self.t_groups\n",
    "            _classes_global = self._classes\n",
    "            model_mu_global = deepcopy(self.model_mu)\n",
    "            model_nu_global = deepcopy(self.model_nu)\n",
    "            te_bootstraps = np.zeros(\n",
    "                shape=(X.shape[0], self.t_groups.shape[0], n_bootstraps)\n",
    "            )\n",
    "\n",
    "            logger.info(\"Bootstrap Confidence Intervals\")\n",
    "            for i in tqdm(range(n_bootstraps)):\n",
    "                te_b = self.bootstrap(X, treatment, y, p, size=bootstrap_size)\n",
    "                te_bootstraps[:, :, i] = te_b\n",
    "\n",
    "            te_lower = np.percentile(te_bootstraps, (self.ate_alpha / 2) * 100, axis=2)\n",
    "            te_upper = np.percentile(\n",
    "                te_bootstraps, (1 - self.ate_alpha / 2) * 100, axis=2\n",
    "            )\n",
    "\n",
    "            # set member variables back to global (currently last bootstrapped outcome)\n",
    "            self.t_groups = t_groups_global\n",
    "            self._classes = _classes_global\n",
    "            self.model_mu = deepcopy(model_mu_global)\n",
    "            self.model_nu = deepcopy(model_nu_global)\n",
    "\n",
    "            return (te, te_lower, te_upper)\n",
    "\n",
    "    def estimate_ate(\n",
    "        self,\n",
    "        X,\n",
    "        treatment,\n",
    "        y,\n",
    "        p=None,\n",
    "        num_samples=5,\n",
    "        bootstrap_ci=False,\n",
    "        n_bootstraps=1000,\n",
    "        bootstrap_size=10000,\n",
    "        pretrain=False,\n",
    "    ):\n",
    "        \"\"\"Estimate the Average Treatment Effect (ATE).\n",
    "\n",
    "        Args:\n",
    "            X (np.matrix or np.array or pd.Dataframe): a feature matrix\n",
    "            treatment (np.array or pd.Series): a treatment vector\n",
    "            y (np.array or pd.Series): an outcome vector\n",
    "            p (np.ndarray or pd.Series or dict, optional): an array of propensity scores of float (0,1) in the\n",
    "                single-treatment case; or, a dictionary of treatment groups that map to propensity vectors of\n",
    "                float (0,1); if None will run ElasticNetPropensityModel() to generate the propensity scores.\n",
    "            num_samples (int): number of pairs for each control observation\n",
    "            bootstrap_ci (bool): whether run bootstrap for confidence intervals\n",
    "            n_bootstraps (int): number of bootstrap iterations\n",
    "            bootstrap_size (int): number of samples per bootstrap\n",
    "            pretrain (bool): whether a model has been fit, default False.\n",
    "        Returns:\n",
    "            The mean and confidence interval (LB, UB) of the ATE estimate.\n",
    "        \"\"\"\n",
    "        if pretrain:\n",
    "            if p is None:\n",
    "                # when p is null, use pretrain propensity score\n",
    "                if not self.propensity:\n",
    "                    raise ValueError(\"no propensity score, please call fit() first\")\n",
    "                te, fhat = self.predict(\n",
    "                    X, treatment, y, return_components=True\n",
    "                )\n",
    "            else:\n",
    "                p = self._format_p(p, self.t_groups)\n",
    "                te, fhat = self.predict(\n",
    "                    X, treatment, y, return_components=True\n",
    "                )\n",
    "        else:\n",
    "            te, fhat = self.fit_predict(\n",
    "                X, treatment, y, num_samples, return_components=True\n",
    "            )\n",
    "        X, treatment, y = convert_pd_to_np(X, treatment, y)\n",
    "\n",
    "        # if p is None:\n",
    "        #     p = self.propensity\n",
    "        # else:\n",
    "        #     p = self._format_p(p, self.t_groups)\n",
    "\n",
    "        ate = np.zeros(self.t_groups.shape[0])\n",
    "        ate_lb = np.zeros(self.t_groups.shape[0])\n",
    "        ate_ub = np.zeros(self.t_groups.shape[0])\n",
    "\n",
    "        ate[0] = te[:, 0].mean()\n",
    "\n",
    "        # for i, group in enumerate(self.t_groups):\n",
    "        #     _ate = te[:, i].mean()\n",
    "\n",
    "        #     mask = (treatment == group) | (treatment == self.control_name)\n",
    "        #     treatment_filt = treatment[mask]\n",
    "        #     w = (treatment_filt == group).astype(int)\n",
    "        #     prob_treatment = float(sum(w)) / w.shape[0]\n",
    "\n",
    "        #     dhat_c = dhat_cs[group][mask]\n",
    "        #     dhat_t = dhat_ts[group][mask]\n",
    "        #     p_filt = p[group][mask]\n",
    "\n",
    "        #     # SE formula is based on the lower bound formula (7) from Imbens, Guido W., and Jeffrey M. Wooldridge. 2009.\n",
    "        #     # \"Recent Developments in the Econometrics of Program Evaluation.\" Journal of Economic Literature\n",
    "        #     se = np.sqrt(\n",
    "        #         (\n",
    "        #             self.vars_t[group] / prob_treatment\n",
    "        #             + self.vars_c[group] / (1 - prob_treatment)\n",
    "        #             + (p_filt * dhat_c + (1 - p_filt) * dhat_t).var()\n",
    "        #         )\n",
    "        #         / w.shape[0]\n",
    "        #     )\n",
    "\n",
    "        #     _ate_lb = _ate - se * norm.ppf(1 - self.ate_alpha / 2)\n",
    "        #     _ate_ub = _ate + se * norm.ppf(1 - self.ate_alpha / 2)\n",
    "\n",
    "        #     ate[i] = _ate\n",
    "        #     ate_lb[i] = _ate_lb\n",
    "        #     ate_ub[i] = _ate_ub\n",
    "\n",
    "        if not bootstrap_ci:\n",
    "            return ate, ate_lb, ate_ub\n",
    "        else:\n",
    "            t_groups_global = self.t_groups\n",
    "            _classes_global = self._classes\n",
    "            model_mu_global = deepcopy(self.model_mu)\n",
    "            model_nu_global = deepcopy(self.model_nu)\n",
    "\n",
    "            logger.info(\"Bootstrap Confidence Intervals for ATE\")\n",
    "            ate_bootstraps = np.zeros(shape=(self.t_groups.shape[0], n_bootstraps))\n",
    "\n",
    "            for n in tqdm(range(n_bootstraps)):\n",
    "                cate_b = self.bootstrap(X, treatment, y, p, size=bootstrap_size)\n",
    "                ate_bootstraps[:, n] = cate_b.mean()\n",
    "\n",
    "            ate_lower = np.percentile(\n",
    "                ate_bootstraps, (self.ate_alpha / 2) * 100, axis=1\n",
    "            )\n",
    "            ate_upper = np.percentile(\n",
    "                ate_bootstraps, (1 - self.ate_alpha / 2) * 100, axis=1\n",
    "            )\n",
    "\n",
    "            # set member variables back to global (currently last bootstrapped outcome)\n",
    "            self.t_groups = t_groups_global\n",
    "            self._classes = _classes_global\n",
    "            self.model_mu = deepcopy(model_mu_global)\n",
    "            self.models_nu = deepcopy(model_nu_global)\n",
    "            return ate, ate_lower, ate_upper\n",
    "\n",
    "class BaseRPRegressor(BaseRPLearner):\n",
    "    \"\"\"\n",
    "    A parent class for PH-learner regressor classes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        learner=None,\n",
    "        outcome_learner=None,\n",
    "        pair_learner=None,\n",
    "        ate_alpha=0.05,\n",
    "        control_name=0,\n",
    "    ):\n",
    "        \"\"\"Initialize a PH-learner regressor.\n",
    "\n",
    "        Args:\n",
    "            learner (optional): a model to estimate outcomes and treatment effects in both the control and treatment\n",
    "                groups\n",
    "            outcome_learner (optional): a model to estimate outcomes\n",
    "            pair_learner (optional): a model to estimate paired treatment effects\n",
    "            ate_alpha (float, optional): the confidence level alpha of the ATE estimate\n",
    "            control_name (str or int, optional): name of control group\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            learner=learner,\n",
    "            outcome_learner=outcome_learner,\n",
    "            pair_learner=pair_learner,\n",
    "            ate_alpha=ate_alpha,\n",
    "            control_name=control_name,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasePDRLearner(BaseLearner):\n",
    "    \"\"\"\n",
    "    A parent class for PDR-learner regressor classes.\n",
    "    PDR-learner estimates treatment effects with machine learning models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        learner=None,\n",
    "        control_outcome_learner=None,\n",
    "        treatment_outcome_learner=None,\n",
    "        treatment_effect_learner=None,\n",
    "        ate_alpha=0.05,\n",
    "        control_name=0,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize a PDR-learner.\n",
    "\n",
    "        Args:\n",
    "            learner (optional): model used for all tasks if specific learners are not provided.\n",
    "            control_outcome_learner (optional): model for control outcomes.\n",
    "            treatment_outcome_learner (optional): model for treated outcomes.\n",
    "            treatment_effect_learner (optional): model for treatment effects.\n",
    "            ate_alpha (float, optional): significance level for ATE CI.\n",
    "            control_name (str or int, optional): label for control group.\n",
    "        \"\"\"\n",
    "        assert (learner is not None) or (\n",
    "            (control_outcome_learner is not None)\n",
    "            and (treatment_outcome_learner is not None)\n",
    "            and (treatment_effect_learner is not None)\n",
    "        )\n",
    "\n",
    "        if control_outcome_learner is None:\n",
    "            self.model_mu_c = deepcopy(learner)\n",
    "        else:\n",
    "            self.model_mu_c = control_outcome_learner\n",
    "\n",
    "        if treatment_outcome_learner is None:\n",
    "            self.model_mu_t = deepcopy(learner)\n",
    "        else:\n",
    "            self.model_mu_t = treatment_outcome_learner\n",
    "\n",
    "        if treatment_effect_learner is None:\n",
    "            self.model_tau = deepcopy(learner)\n",
    "        else:\n",
    "            self.model_tau = treatment_effect_learner\n",
    "\n",
    "        self.ate_alpha = ate_alpha\n",
    "        self.control_name = control_name\n",
    "\n",
    "        self.propensity = None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            \"{}(control_outcome_learner={},\\n\"\n",
    "            \"\\ttreatment_outcome_learner={},\\n\"\n",
    "            \"\\ttreatment_effect_learner={})\".format(\n",
    "                self.__class__.__name__,\n",
    "                self.model_mu_c.__repr__(),\n",
    "                self.model_mu_t.__repr__(),\n",
    "                self.model_tau.__repr__(),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def fit(self, X, treatment, y, p=None, seed=None):\n",
    "        \"\"\"\n",
    "        Fit the PDR-learner with the doubly robust pairwise estimator.\n",
    "\n",
    "        Args:\n",
    "            X (np.array or pd.DataFrame): feature matrix.\n",
    "            treatment (np.array or pd.Series): treatment vector.\n",
    "            y (np.array or pd.Series): outcome vector.\n",
    "            p (optional): propensity scores; if None, they are estimated.\n",
    "            seed (int): random seed.\n",
    "        \"\"\"\n",
    "        X, treatment, y = convert_pd_to_np(X, treatment, y)\n",
    "        check_treatment_vector(treatment, self.control_name)\n",
    "        self.t_groups = np.unique(treatment[treatment != self.control_name])\n",
    "        self.t_groups.sort()\n",
    "        self._classes = {group: i for i, group in enumerate(self.t_groups)}\n",
    "\n",
    "        # Use 3-fold cross-fitting\n",
    "        cv = KFold(n_splits=3, shuffle=True, random_state=seed)\n",
    "        split_indices = [index for _, index in cv.split(y)]\n",
    "\n",
    "        self.models_mu_c = [deepcopy(self.model_mu_c) for _ in range(3)]\n",
    "        self.models_mu_t = {\n",
    "            group: [deepcopy(self.model_mu_t) for _ in range(3)]\n",
    "            for group in self.t_groups\n",
    "        }\n",
    "        self.models_tau = {\n",
    "            group: [deepcopy(self.model_tau) for _ in range(3)]\n",
    "            for group in self.t_groups\n",
    "        }\n",
    "\n",
    "        # Initialize propensity score container if not provided\n",
    "        if p is None:\n",
    "            self.propensity = {group: np.zeros(y.shape[0]) for group in self.t_groups}\n",
    "\n",
    "        # Cross-fit\n",
    "        for ifold in range(3):\n",
    "            treatment_idx = split_indices[ifold]\n",
    "            outcome_idx = split_indices[(ifold + 1) % 3]\n",
    "            tau_idx = split_indices[(ifold + 2) % 3]\n",
    "\n",
    "            treatment_treat = treatment[treatment_idx]\n",
    "            treatment_out = treatment[outcome_idx]\n",
    "            treatment_tau = treatment[tau_idx]\n",
    "\n",
    "            y_out, y_tau = y[outcome_idx], y[tau_idx]\n",
    "            X_treat, X_out, X_tau = X[treatment_idx], X[outcome_idx], X[tau_idx]\n",
    "\n",
    "            # Propensity score estimation if not provided\n",
    "            if p is None:\n",
    "                logger.info(\"Estimating propensity scores\")\n",
    "                cur_p = dict()\n",
    "                for group in self.t_groups:\n",
    "                    mask = (treatment_treat == group) | (treatment_treat == self.control_name)\n",
    "                    X_filt = X_treat[mask]\n",
    "                    treatment_filt = treatment_treat[mask]\n",
    "                    w_filt = (treatment_filt == group).astype(int)\n",
    "                    # Compute propensity scores for group 'group'\n",
    "                    cur_p[group], _ = compute_propensity_score(\n",
    "                        X=X_filt, treatment=w_filt, X_pred=X_tau, treatment_pred=(treatment_tau == group).astype(int)\n",
    "                    )\n",
    "                    self.propensity[group][tau_idx] = cur_p[group]\n",
    "            else:\n",
    "                cur_p = dict()\n",
    "                if isinstance(p, (np.ndarray, pd.Series)):\n",
    "                    cur_p = {self.t_groups[0]: convert_pd_to_np(p[tau_idx])}\n",
    "                else:\n",
    "                    cur_p = {g: p[g][tau_idx] for g in self.t_groups}\n",
    "                check_p_conditions(cur_p, self.t_groups)\n",
    "\n",
    "            # Outcome regression: fit control and treatment models on outcome fold\n",
    "            logger.info(\"Fitting outcome regressions\")\n",
    "            # Fit control outcome model on control units\n",
    "            self.models_mu_c[ifold].fit(\n",
    "                X_out[treatment_out == self.control_name],\n",
    "                y_out[treatment_out == self.control_name],\n",
    "            )\n",
    "            for group in self.t_groups:\n",
    "                # Fit treated outcome model for each group\n",
    "                self.models_mu_t[group][ifold].fit(\n",
    "                    X_out[treatment_out == group],\n",
    "                    y_out[treatment_out == group],\n",
    "                )\n",
    "\n",
    "            # Fit pseudo outcomes for treatment effect using doubly robust pairwise estimator\n",
    "            logger.info(\"Fitting doubly robust pairwise pseudo outcomes\")\n",
    "            for group in self.t_groups:\n",
    "                # Filter tau-fold: keep observations from control or group 'group'\n",
    "                mask = (treatment_tau == group) | (treatment_tau == self.control_name)\n",
    "                X_filt = X_tau[mask]\n",
    "                y_filt = y_tau[mask]\n",
    "                p_filt = cur_p[group][mask]\n",
    "                # Predict outcomes using outcome models\n",
    "                mu_c_all = self.models_mu_c[ifold].predict(X_filt)\n",
    "                mu_t_all = self.models_mu_t[group][ifold].predict(X_filt)\n",
    "\n",
    "                # Separate into control and treated subsets for pairing\n",
    "                mask_control = (treatment_tau[mask] == self.control_name)\n",
    "                mask_treated = (treatment_tau[mask] == group)\n",
    "                if np.sum(mask_control) == 0 or np.sum(mask_treated) == 0:\n",
    "                    logger.warning(\"Not enough data for pairing in group {}\".format(group))\n",
    "                    continue\n",
    "\n",
    "                X_control = X_filt[mask_control]\n",
    "                y_control = y_filt[mask_control]\n",
    "                p_control = p_filt[mask_control]\n",
    "                mu_control = mu_c_all[mask_control]\n",
    "\n",
    "                X_treated = X_filt[mask_treated]\n",
    "                y_treated = y_filt[mask_treated]\n",
    "                p_treated = p_filt[mask_treated]\n",
    "                mu_treated = mu_t_all[mask_treated]\n",
    "\n",
    "                scaler = MinMaxScaler()\n",
    "\n",
    "                X_control_scaled = scaler.fit_transform(X_control)\n",
    "                X_treated_scaled = scaler.fit_transform(X_treated)\n",
    "\n",
    "                # Build KDTree on the control group\n",
    "                tree = cKDTree(X_control_scaled)\n",
    "\n",
    "                k = 10\n",
    "\n",
    "                # Find the nearest control neighbour for each treated sample\n",
    "                distances, idx_control = tree.query(X_treated_scaled, k=k)  # k=10\n",
    "\n",
    "                # Expand treated indices to match the number of pairs (each treated unit repeats k times)\n",
    "                idx_treated = np.repeat(np.arange(len(X_treated)), k)\n",
    "                idx_control = idx_control.flatten()  # Flatten to align with repeated treated indices\n",
    "\n",
    "\n",
    "                # Compute the doubly robust pairwise pseudo outcome for each pair:\n",
    "                #   dr_pair = [mu_treated - mu_control] +\n",
    "                #             [ (y_treated - mu_treated) / p_treated - (y_control - mu_control) / (1-p_control) ]\n",
    "                dr_pairs = (\n",
    "                    (mu_treated[idx_treated] - mu_control[idx_control])\n",
    "                    + ((y_treated[idx_treated] - mu_treated[idx_treated]) / p_treated[idx_treated]\n",
    "                       - (y_control[idx_control] - mu_control[idx_control]) / (1 - p_control[idx_control]))\n",
    "                )\n",
    "                # Combine the paired features. Here we simply concatenate the control and treated features.\n",
    "                X_pairs = np.hstack([X_control[idx_control], X_treated[idx_treated]])\n",
    "                # Fit the treatment effect learner on the paired data and doubly robust pseudo outcomes.\n",
    "                self.models_tau[group][ifold].fit(X_pairs, dr_pairs)\n",
    "\n",
    "    def predict(self, X, treatment=None, y=None, p=None, return_components=False, verbose=True):\n",
    "        \"\"\"\n",
    "        Predict treatment effects.\n",
    "        Args:\n",
    "            X (np.array or pd.DataFrame): feature matrix.\n",
    "            treatment (optional): treatment vector.\n",
    "            y (optional): outcome vector.\n",
    "            return_components (bool): if True, return predicted outcomes for control and treated separately.\n",
    "            verbose (bool): whether to output logs.\n",
    "        Returns:\n",
    "            np.array: predicted treatment effects.\n",
    "        \"\"\"\n",
    "        X, treatment, y = convert_pd_to_np(X, treatment, y)\n",
    "        te = np.zeros((X.shape[0], len(self.t_groups)))\n",
    "        yhat_cs = {}\n",
    "        yhat_ts = {}\n",
    "\n",
    "        for i, group in enumerate(self.t_groups):\n",
    "            # Average the treatment effect predictions from the cross-fit models\n",
    "            models_tau = self.models_tau[group]\n",
    "            _te = np.r_[[model.predict(np.hstack([X, X])) for model in models_tau]].mean(axis=0)\n",
    "            te[:, i] = np.ravel(_te)\n",
    "            yhat_cs[group] = np.r_[\n",
    "                [model.predict(X) for model in self.models_mu_c]\n",
    "            ].mean(axis=0)\n",
    "            yhat_ts[group] = np.r_[\n",
    "                [model.predict(X) for model in self.models_mu_t[group]]\n",
    "            ].mean(axis=0)\n",
    "\n",
    "            if (y is not None) and (treatment is not None) and verbose:\n",
    "                mask = (treatment == group) | (treatment == self.control_name)\n",
    "                treatment_filt = treatment[mask]\n",
    "                y_filt = y[mask]\n",
    "                w = (treatment_filt == group).astype(int)\n",
    "                yhat = np.zeros_like(y_filt, dtype=float)\n",
    "                yhat[w == 0] = yhat_cs[group][mask][w == 0]\n",
    "                yhat[w == 1] = yhat_ts[group][mask][w == 1]\n",
    "                logger.info(\"Error metrics for group {}\".format(group))\n",
    "                regression_metrics(y_filt, yhat, w)\n",
    "        if not return_components:\n",
    "            return te\n",
    "        else:\n",
    "            return te, yhat_cs, yhat_ts\n",
    "\n",
    "    def fit_predict(\n",
    "        self,\n",
    "        X,\n",
    "        treatment,\n",
    "        y,\n",
    "        p=None,\n",
    "        return_ci=False,\n",
    "        n_bootstraps=1000,\n",
    "        bootstrap_size=10000,\n",
    "        return_components=False,\n",
    "        verbose=True,\n",
    "        seed=None,\n",
    "    ):\n",
    "        \"\"\"Fit the treatment effect and outcome models of the R learner and predict treatment effects.\n",
    "\n",
    "        Args:\n",
    "            X (np.matrix or np.array or pd.Dataframe): a feature matrix\n",
    "            treatment (np.array or pd.Series): a treatment vector\n",
    "            y (np.array or pd.Series): an outcome vector\n",
    "            p (np.ndarray or pd.Series or dict, optional): an array of propensity scores of float (0,1) in the\n",
    "                single-treatment case; or, a dictionary of treatment groups that map to propensity vectors of\n",
    "                float (0,1); if None will run ElasticNetPropensityModel() to generate the propensity scores.\n",
    "            return_ci (bool): whether to return confidence intervals\n",
    "            n_bootstraps (int): number of bootstrap iterations\n",
    "            bootstrap_size (int): number of samples per bootstrap\n",
    "            return_components (bool, optional): whether to return outcome for treatment and control seperately\n",
    "            verbose (str): whether to output progress logs\n",
    "            seed (int): random seed for cross-fitting\n",
    "        Returns:\n",
    "            (numpy.ndarray): Predictions of treatment effects. Output dim: [n_samples, n_treatment]\n",
    "                If return_ci, returns CATE [n_samples, n_treatment], LB [n_samples, n_treatment],\n",
    "                UB [n_samples, n_treatment]\n",
    "        \"\"\"\n",
    "        X, treatment, y = convert_pd_to_np(X, treatment, y)\n",
    "        self.fit(X, treatment, y, p, seed)\n",
    "\n",
    "        if p is None:\n",
    "            p = self.propensity\n",
    "\n",
    "        check_p_conditions(p, self.t_groups)\n",
    "        if isinstance(p, (np.ndarray, pd.Series)):\n",
    "            treatment_name = self.t_groups[0]\n",
    "            p = {treatment_name: convert_pd_to_np(p)}\n",
    "        elif isinstance(p, dict):\n",
    "            p = {\n",
    "                treatment_name: convert_pd_to_np(_p) for treatment_name, _p in p.items()\n",
    "            }\n",
    "\n",
    "        te = self.predict(\n",
    "            X, treatment=treatment, y=y, return_components=return_components\n",
    "        )\n",
    "\n",
    "        if not return_ci:\n",
    "            return te\n",
    "        else:\n",
    "            t_groups_global = self.t_groups\n",
    "            _classes_global = self._classes\n",
    "            models_mu_c_global = deepcopy(self.models_mu_c)\n",
    "            models_mu_t_global = deepcopy(self.models_mu_t)\n",
    "            models_tau_global = deepcopy(self.models_tau)\n",
    "            te_bootstraps = np.zeros(\n",
    "                shape=(X.shape[0], self.t_groups.shape[0], n_bootstraps)\n",
    "            )\n",
    "\n",
    "            logger.info(\"Bootstrap Confidence Intervals\")\n",
    "            for i in tqdm(range(n_bootstraps)):\n",
    "                te_b = self.bootstrap(X, treatment, y, p, size=bootstrap_size)\n",
    "                te_bootstraps[:, :, i] = te_b\n",
    "\n",
    "            te_lower = np.percentile(te_bootstraps, (self.ate_alpha / 2) * 100, axis=2)\n",
    "            te_upper = np.percentile(\n",
    "                te_bootstraps, (1 - self.ate_alpha / 2) * 100, axis=2\n",
    "            )\n",
    "\n",
    "            # set member variables back to global (currently last bootstrapped outcome)\n",
    "            self.t_groups = t_groups_global\n",
    "            self._classes = _classes_global\n",
    "            self.models_mu_c = deepcopy(models_mu_c_global)\n",
    "            self.models_mu_t = deepcopy(models_mu_t_global)\n",
    "            self.models_tau = deepcopy(models_tau_global)\n",
    "\n",
    "            return (te, te_lower, te_upper)\n",
    "\n",
    "    def estimate_ate(\n",
    "        self,\n",
    "        X,\n",
    "        treatment,\n",
    "        y,\n",
    "        p=None,\n",
    "        bootstrap_ci=False,\n",
    "        n_bootstraps=1000,\n",
    "        bootstrap_size=10000,\n",
    "        seed=None,\n",
    "        pretrain=False,\n",
    "    ):\n",
    "        \"\"\"Estimate the Average Treatment Effect (ATE).\n",
    "\n",
    "        Args:\n",
    "            X (np.matrix or np.array or pd.Dataframe): a feature matrix\n",
    "            treatment (np.array or pd.Series): a treatment vector\n",
    "            y (np.array or pd.Series): an outcome vector\n",
    "            p (np.ndarray or pd.Series or dict, optional): an array of propensity scores of float (0,1) in the\n",
    "                single-treatment case; or, a dictionary of treatment groups that map to propensity vectors of\n",
    "                float (0,1); if None will run ElasticNetPropensityModel() to generate the propensity scores.\n",
    "            bootstrap_ci (bool): whether run bootstrap for confidence intervals\n",
    "            n_bootstraps (int): number of bootstrap iterations\n",
    "            bootstrap_size (int): number of samples per bootstrap\n",
    "            seed (int): random seed for cross-fitting\n",
    "            pretrain (bool): whether a model has been fit, default False.\n",
    "        Returns:\n",
    "            The mean and confidence interval (LB, UB) of the ATE estimate.\n",
    "        \"\"\"\n",
    "        if pretrain:\n",
    "            te, yhat_cs, yhat_ts = self.predict(\n",
    "                X, treatment, y, p, return_components=True\n",
    "            )\n",
    "        else:\n",
    "            te, yhat_cs, yhat_ts = self.fit_predict(\n",
    "                X, treatment, y, p, return_components=True, seed=seed\n",
    "            )\n",
    "        X, treatment, y = convert_pd_to_np(X, treatment, y)\n",
    "\n",
    "        if p is None:\n",
    "            p = self.propensity\n",
    "        else:\n",
    "            check_p_conditions(p, self.t_groups)\n",
    "        if isinstance(p, (np.ndarray, pd.Series)):\n",
    "            treatment_name = self.t_groups[0]\n",
    "            p = {treatment_name: convert_pd_to_np(p)}\n",
    "        elif isinstance(p, dict):\n",
    "            p = {\n",
    "                treatment_name: convert_pd_to_np(_p) for treatment_name, _p in p.items()\n",
    "            }\n",
    "\n",
    "        ate = np.zeros(self.t_groups.shape[0])\n",
    "        ate_lb = np.zeros(self.t_groups.shape[0])\n",
    "        ate_ub = np.zeros(self.t_groups.shape[0])\n",
    "\n",
    "        for i, group in enumerate(self.t_groups):\n",
    "            _ate = te[:, i].mean()\n",
    "\n",
    "            mask = (treatment == group) | (treatment == self.control_name)\n",
    "            treatment_filt = treatment[mask]\n",
    "            w = (treatment_filt == group).astype(int)\n",
    "            prob_treatment = float(sum(w)) / w.shape[0]\n",
    "\n",
    "            yhat_c = yhat_cs[group][mask]\n",
    "            yhat_t = yhat_ts[group][mask]\n",
    "            y_filt = y[mask]\n",
    "\n",
    "            # SE formula is based on the lower bound formula (7) from Imbens, Guido W., and Jeffrey M. Wooldridge. 2009.\n",
    "            # \"Recent Developments in the Econometrics of Program Evaluation.\" Journal of Economic Literature\n",
    "            se = np.sqrt(\n",
    "                (\n",
    "                    (y_filt[w == 0] - yhat_c[w == 0]).var() / (1 - prob_treatment)\n",
    "                    + (y_filt[w == 1] - yhat_t[w == 1]).var() / prob_treatment\n",
    "                    + (yhat_t - yhat_c).var()\n",
    "                )\n",
    "                / y_filt.shape[0]\n",
    "            )\n",
    "\n",
    "            _ate_lb = _ate - se * norm.ppf(1 - self.ate_alpha / 2)\n",
    "            _ate_ub = _ate + se * norm.ppf(1 - self.ate_alpha / 2)\n",
    "\n",
    "            ate[i] = _ate\n",
    "            ate_lb[i] = _ate_lb\n",
    "            ate_ub[i] = _ate_ub\n",
    "\n",
    "        if not bootstrap_ci:\n",
    "            return ate, ate_lb, ate_ub\n",
    "        else:\n",
    "            t_groups_global = self.t_groups\n",
    "            _classes_global = self._classes\n",
    "            models_mu_c_global = deepcopy(self.models_mu_c)\n",
    "            models_mu_t_global = deepcopy(self.models_mu_t)\n",
    "            models_tau_global = deepcopy(self.models_tau)\n",
    "\n",
    "            logger.info(\"Bootstrap Confidence Intervals for ATE\")\n",
    "            ate_bootstraps = np.zeros(shape=(self.t_groups.shape[0], n_bootstraps))\n",
    "\n",
    "            for n in tqdm(range(n_bootstraps)):\n",
    "                cate_b = self.bootstrap(\n",
    "                    X, treatment, y, p, size=bootstrap_size, seed=seed\n",
    "                )\n",
    "                ate_bootstraps[:, n] = cate_b.mean()\n",
    "\n",
    "            ate_lower = np.percentile(\n",
    "                ate_bootstraps, (self.ate_alpha / 2) * 100, axis=1\n",
    "            )\n",
    "            ate_upper = np.percentile(\n",
    "                ate_bootstraps, (1 - self.ate_alpha / 2) * 100, axis=1\n",
    "            )\n",
    "\n",
    "            # set member variables back to global (currently last bootstrapped outcome)\n",
    "            self.t_groups = t_groups_global\n",
    "            self._classes = _classes_global\n",
    "            self.models_mu_c = deepcopy(models_mu_c_global)\n",
    "            self.models_mu_t = deepcopy(models_mu_t_global)\n",
    "            self.models_tau = deepcopy(models_tau_global)\n",
    "            return ate, ate_lower, ate_upper\n",
    "\n",
    "\n",
    "class BasePDRRegressor(BasePDRLearner):\n",
    "    \"\"\"\n",
    "    A parent class for PDR-learner regressor classes.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        learner=None,\n",
    "        control_outcome_learner=None,\n",
    "        treatment_outcome_learner=None,\n",
    "        treatment_effect_learner=None,\n",
    "        ate_alpha=0.05,\n",
    "        control_name=0,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            learner=learner,\n",
    "            control_outcome_learner=control_outcome_learner,\n",
    "            treatment_outcome_learner=treatment_outcome_learner,\n",
    "            treatment_effect_learner=treatment_effect_learner,\n",
    "            ate_alpha=ate_alpha,\n",
    "            control_name=control_name,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "\n",
    "# Create the neural network\n",
    "def _build_mlp(input_dim, hidden_dims, output_dim=1, activation=nn.ReLU):\n",
    "    \"\"\"Builds a simple MLP.\"\"\"\n",
    "    layers = []\n",
    "    last_dim = input_dim\n",
    "    for hidden_dim in hidden_dims:\n",
    "        layers.append(nn.Linear(last_dim, hidden_dim))\n",
    "        layers.append(activation())\n",
    "        last_dim = hidden_dim\n",
    "    layers.append(nn.Linear(last_dim, output_dim))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "# Class for pairs\n",
    "class PairDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset to serve pairs of indices.\"\"\"\n",
    "    def __init__(self, pairs):\n",
    "        self.pairs = pairs # List of tuples (idx_i, idx_j)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return the pair of original indices\n",
    "        return self.pairs[idx]\n",
    "\n",
    "# PairNet implementation using PyTorch\n",
    "class PairNetTorch:\n",
    "    \"\"\"\n",
    "    PairNet implementation using PyTorch.\n",
    "\n",
    "    Uses a T-Learner architecture (separate networks for control and treatment)\n",
    "    trained jointly with the loss: ((y_i - y_j) - (mu(xi, ti) - mu(xj, tj)))^2\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 input_dim: int,\n",
    "                 hidden_dims: list = [64, 32],\n",
    "                 activation = nn.ReLU,\n",
    "                 learning_rate: float = 1e-3,\n",
    "                 weight_decay: float = 1e-4,\n",
    "                 epochs: int = 100,\n",
    "                 batch_size: int = 200,\n",
    "                 distance_threshold: float = np.inf,\n",
    "                 num_neighbours: int = 3, \n",
    "                 val_size: float = 0.0, # proportion used for validation, in [0,1]\n",
    "                 patience: int = 10,     # Early stopping patience\n",
    "                 verbose: int = 10,     # Print loss every `verbose` epochs\n",
    "                 random_state: int | None = None,\n",
    "                 device: str | None = None):\n",
    "        \"\"\"\n",
    "        Initialize the PairNet learner.\n",
    "\n",
    "        Args:\n",
    "            input_dim (int): Number of features in X.\n",
    "            hidden_dims (list, optional): List of hidden layer sizes for mu_c and mu_t.\n",
    "                                          Defaults to [64, 32].\n",
    "            activation (torch.nn.Module, optional): Activation function. Defaults to nn.ReLU.\n",
    "            learning_rate (float, optional): Optimizer learning rate. Defaults to 1e-3.\n",
    "            weight_decay (float, optional): L2 regularization strength. Defaults to 1e-4.\n",
    "            epochs (int, optional): Number of training epochs. Defaults to 100.\n",
    "            batch_size (int, optional): Batch size for training pairs. Defaults to 200.\n",
    "            distance_threshold (float, optional): Max distance for pairing. Defaults to no max distance.\n",
    "            num_neighbours (int, optional): neighbours per sample in pairing. Defaults to 3.\n",
    "            val_size (float, optional): Fraction of data to use for validation/early stopping.\n",
    "                                        If 0, no validation/early stopping is used. Defaults to 0.\n",
    "            patience (int, optional): Early stopping patience (epochs without improvement). Defaults to 10.\n",
    "            verbose (int, optional): Print loss frequency (epochs). Defaults to 10.\n",
    "            random_state (int | None, optional): Random seed. Defaults to None.\n",
    "            device (str | None, optional): Device ('cpu', 'cuda'). Autodetects if None.\n",
    "        \"\"\"\n",
    "        \n",
    "        if random_state is not None:\n",
    "            torch.manual_seed(random_state)\n",
    "            np.random.seed(random_state)\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.activation = activation\n",
    "        self.lr = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.distance_threshold = distance_threshold\n",
    "        self.num_neighbours = num_neighbours\n",
    "        self.val_size = val_size\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.random_state = random_state\n",
    "        self.rng = np.random.default_rng(random_state)\n",
    "\n",
    "        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        # Initialize models, optimizers, scaler\n",
    "        self.mu_c = _build_mlp(input_dim, hidden_dims, 1, activation).to(self.device)\n",
    "        self.mu_t = _build_mlp(input_dim, hidden_dims, 1, activation).to(self.device)\n",
    "\n",
    "        # Combine parameters for a single optimizer pass\n",
    "        all_params = list(self.mu_c.parameters()) + list(self.mu_t.parameters())\n",
    "        self.optimizer = optim.Adam(all_params, lr=self.lr, weight_decay=self.weight_decay)\n",
    "\n",
    "        self.scaler = StandardScaler() # Scale features for NN stability\n",
    "\n",
    "        # Placeholders for data and results\n",
    "        self.X_tensor = None\n",
    "        self.t_tensor = None\n",
    "        self.y_tensor = None\n",
    "        self.pairs_train = []\n",
    "        self.pairs_val = []\n",
    "        self.best_val_loss = np.inf\n",
    "        self.epochs_no_improve = 0\n",
    "        self.best_mu_c_state = None\n",
    "        self.best_mu_t_state = None\n",
    "\n",
    "\n",
    "    def _softmax(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Numerically stable softmax function.\"\"\"\n",
    "        if x.size == 0: \n",
    "            return np.array([])\n",
    "        return softmax(x)\n",
    "\n",
    "    def _create_pairs_torch(self, X_np: np.ndarray, t_np: np.ndarray) -> list[tuple[int, int]]:\n",
    "        \"\"\"\n",
    "        Creates pairs based on distance in the original feature space.\n",
    "        Returns a list of (idx_i, idx_j) tuples.\n",
    "        \"\"\"\n",
    "        n_samples = X_np.shape[0]\n",
    "        idx = np.arange(n_samples)\n",
    "        idx_c = idx[t_np == 0]\n",
    "        idx_t = idx[t_np == 1]\n",
    "\n",
    "        if len(idx_c) == 0 or len(idx_t) == 0:\n",
    "            print(\"Warning: No samples in control or treatment group for pairing.\")\n",
    "            return []\n",
    "\n",
    "        X_c = X_np[idx_c]\n",
    "        X_t = X_np[idx_t]\n",
    "\n",
    "        all_pairs = [] # List of (original_index_i, original_index_j)\n",
    "\n",
    "        # --- Function to process one direction (e.g., target=Treated, pool=Control) ---\n",
    "        def find_pairs_one_direction(target_indices, target_X, pool_indices, pool_X):\n",
    "            local_pairs = []\n",
    "            if len(target_X) == 0 or len(pool_X) == 0:\n",
    "                return local_pairs\n",
    "\n",
    "            distances = cdist(target_X, pool_X, metric='euclidean')\n",
    "\n",
    "            for i in range(len(target_X)):\n",
    "                dists_i = distances[i, :]\n",
    "                original_target_idx = target_indices[i]\n",
    "\n",
    "                # Softmax Sampling Logic\n",
    "                potential_neighbour_indices = np.where(dists_i <= self.distance_threshold)[0]\n",
    "                if len(potential_neighbour_indices) == 0: \n",
    "                    continue\n",
    "\n",
    "                valid_distances = dists_i[potential_neighbour_indices]\n",
    "                neg_distances = -valid_distances\n",
    "                probs = self._softmax(neg_distances)\n",
    "                if np.any(np.isnan(probs)) or not np.isclose(np.sum(probs), 1.0): \n",
    "                    probs = None\n",
    "\n",
    "                num_to_sample = min(self.num_neighbours, len(potential_neighbour_indices))\n",
    "                if num_to_sample == 0: \n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    sampled_local_indices = self.rng.choice(\n",
    "                        potential_neighbour_indices, size=num_to_sample, replace=True, p=probs\n",
    "                    )\n",
    "                except ValueError as e: # Catch potential issue with p summing slightly off 1.0\n",
    "                    print(f\"Warning: RNG choice error (likely prob sum issue) for sample {original_target_idx}: {e}. Sampling uniformly.\")\n",
    "                    sampled_local_indices = self.rng.choice(\n",
    "                        potential_neighbour_indices, size=num_to_sample, replace=True # Uniform sampling\n",
    "                    )\n",
    "\n",
    "                for local_idx in sampled_local_indices:\n",
    "                    original_pool_idx = pool_indices[local_idx]\n",
    "                    local_pairs.append((original_target_idx, original_pool_idx))\n",
    "\n",
    "            return local_pairs\n",
    "\n",
    "        # Find pairs for treated units (target=Treated, pool=Control)\n",
    "        pairs_tc = find_pairs_one_direction(idx_t, X_t, idx_c, X_c)\n",
    "        all_pairs.extend(pairs_tc)\n",
    "\n",
    "        # Find pairs for control units (target=Control, pool=Treated)\n",
    "        pairs_ct = find_pairs_one_direction(idx_c, X_c, idx_t, X_t)\n",
    "        all_pairs.extend(pairs_ct)\n",
    "\n",
    "        return all_pairs\n",
    "\n",
    "    def _get_predictions_for_pair(self, x_i, t_i, x_j, t_j):\n",
    "        \"\"\"Gets mu(x,t) predictions for both elements of pairs in a batch.\"\"\"\n",
    "        # Predict all i's and j's under both control and treatment scenarios\n",
    "        pred_i_c = self.mu_c(x_i)\n",
    "        pred_i_t = self.mu_t(x_i)\n",
    "        pred_j_c = self.mu_c(x_j)\n",
    "        pred_j_t = self.mu_t(x_j)\n",
    "\n",
    "        # Select the correct prediction based on actual treatment\n",
    "        t_i_mask = t_i.bool() # Convert to boolean mask\n",
    "        t_j_mask = t_j.bool()\n",
    "\n",
    "        pred_i = torch.where(t_i_mask, pred_i_t, pred_i_c)\n",
    "        pred_j = torch.where(t_j_mask, pred_j_t, pred_j_c)\n",
    "\n",
    "        return pred_i, pred_j\n",
    "\n",
    "    def _calculate_loss(self, idx_i_batch, idx_j_batch):\n",
    "        \"\"\"Calculates the pair loss for a batch of pairs.\"\"\"\n",
    "        # Retrieve data for the batch using indices\n",
    "        x_i = self.X_tensor[idx_i_batch]\n",
    "        t_i = self.t_tensor[idx_i_batch]\n",
    "        y_i = self.y_tensor[idx_i_batch]\n",
    "\n",
    "        x_j = self.X_tensor[idx_j_batch]\n",
    "        t_j = self.t_tensor[idx_j_batch]\n",
    "        y_j = self.y_tensor[idx_j_batch]\n",
    "\n",
    "        # Get predictions\n",
    "        pred_i, pred_j = self._get_predictions_for_pair(x_i, t_i, x_j, t_j)\n",
    "\n",
    "        # Calculate the pair loss\n",
    "        true_diff = y_i - y_j\n",
    "        pred_diff = pred_i - pred_j\n",
    "        loss = torch.mean((true_diff - pred_diff) ** 2) \n",
    "        return loss\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, treatment: pd.Series, y: pd.Series, total_time=None):\n",
    "        \"\"\"\n",
    "        Fit the PairNet model using the pair loss.\n",
    "\n",
    "        Args:\n",
    "            X (pd.DataFrame): Feature matrix.\n",
    "            treatment (pd.Series): Treatment assignment vector (0 or 1).\n",
    "            y (pd.Series): Outcome vector.\n",
    "            total_time (float): Time allowed to run.\n",
    "        \"\"\"\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "\n",
    "        # Preprocessing and Data Setup\n",
    "        X, treatment, y = convert_pd_to_np(X, treatment, y)\n",
    "        X_np = self.scaler.fit_transform(X).astype(np.float32)\n",
    "        t_np = treatment.astype(np.float32).reshape(-1, 1) # Ensure shape [n, 1]\n",
    "        y_np = y.astype(np.float32).reshape(-1, 1)       # Ensure shape [n, 1]\n",
    "\n",
    "        self.X_tensor = torch.tensor(X_np, dtype=torch.float32).to(self.device)\n",
    "        self.t_tensor = torch.tensor(t_np, dtype=torch.float32).to(self.device)\n",
    "        self.y_tensor = torch.tensor(y_np, dtype=torch.float32).to(self.device)\n",
    "\n",
    "        # Create pairs\n",
    "        all_pairs = self._create_pairs_torch(X_np, t_np.flatten())\n",
    "        if not all_pairs:\n",
    "            raise ValueError(\"No pairs were created. Cannot train the model.\")\n",
    "\n",
    "        # Split pairs for Train/Validation (if val_size > 0)\n",
    "        if self.val_size > 0:\n",
    "            if len(all_pairs) < 2 / self.val_size or len(all_pairs) < 2 / (1 - self.val_size): # Ensure enough pairs for split\n",
    "                 print(\"Warning: Not enough pairs for validation split, disabling validation.\")\n",
    "                 self.val_size = 0\n",
    "                 self.pairs_train = all_pairs\n",
    "                 self.pairs_val = []\n",
    "            else:\n",
    "                 pairs_train_idx, pairs_val_idx = train_test_split(\n",
    "                    np.arange(len(all_pairs)), test_size=self.val_size, random_state=self.random_state\n",
    "                 )\n",
    "                 self.pairs_train = [all_pairs[i] for i in pairs_train_idx]\n",
    "                 self.pairs_val = [all_pairs[i] for i in pairs_val_idx]\n",
    "        else:\n",
    "             self.pairs_train = all_pairs\n",
    "             self.pairs_val = []\n",
    "\n",
    "        train_dataset = PairDataset(self.pairs_train)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        if self.pairs_val:\n",
    "            val_dataset = PairDataset(self.pairs_val)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=self.batch_size)\n",
    "\n",
    "\n",
    "        # Training Loop\n",
    "        self.mu_c.train()\n",
    "        self.mu_t.train()\n",
    "        self.best_val_loss = np.inf\n",
    "        self.epochs_no_improve = 0\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            epoch_train_loss = 0.0\n",
    "            for i, (idx_i_batch, idx_j_batch) in enumerate(train_loader):\n",
    "                idx_i_batch = idx_i_batch.long()\n",
    "                idx_j_batch = idx_j_batch.long()\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss = self._calculate_loss(idx_i_batch, idx_j_batch)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                epoch_train_loss += loss.item()\n",
    "\n",
    "            avg_epoch_train_loss = epoch_train_loss / len(train_loader)\n",
    "\n",
    "            # Validation and Early Stopping\n",
    "            avg_epoch_val_loss = -1\n",
    "            if self.pairs_val:\n",
    "                self.mu_c.eval()\n",
    "                self.mu_t.eval()\n",
    "                epoch_val_loss = 0.0\n",
    "                with torch.no_grad():\n",
    "                    for idx_i_batch, idx_j_batch in val_loader:\n",
    "                        idx_i_batch = idx_i_batch.long()\n",
    "                        idx_j_batch = idx_j_batch.long()\n",
    "                        loss = self._calculate_loss(idx_i_batch, idx_j_batch)\n",
    "                        epoch_val_loss += loss.item()\n",
    "                avg_epoch_val_loss = epoch_val_loss / len(val_loader)\n",
    "\n",
    "                if avg_epoch_val_loss < self.best_val_loss:\n",
    "                    self.best_val_loss = avg_epoch_val_loss\n",
    "                    self.epochs_no_improve = 0\n",
    "                    # Store the best model state\n",
    "                    self.best_mu_c_state = self.mu_c.state_dict()\n",
    "                    self.best_mu_t_state = self.mu_t.state_dict()\n",
    "                else:\n",
    "                    self.epochs_no_improve += 1\n",
    "\n",
    "                # Set back to train mode\n",
    "                self.mu_c.train()\n",
    "                self.mu_t.train()\n",
    "\n",
    "            if self.verbose > 0 and (epoch + 1) % self.verbose == 0:\n",
    "                if self.pairs_val:\n",
    "                    print(f\"Epoch [{epoch+1}/{self.epochs}], Train Loss: {avg_epoch_train_loss:.4f}, Val Loss: {avg_epoch_val_loss:.4f}\")\n",
    "                else:\n",
    "                    print(f\"Epoch [{epoch+1}/{self.epochs}], Train Loss: {avg_epoch_train_loss:.4f}\")\n",
    "\n",
    "            if self.val_size > 0 and self.epochs_no_improve >= self.patience:\n",
    "                #print(f\"Early stopping triggered after epoch {epoch+1}. Best Val Loss: {self.best_val_loss:.4f}\")\n",
    "                # Load the best model state before breaking\n",
    "                if self.best_mu_c_state and self.best_mu_t_state:\n",
    "                    self.mu_c.load_state_dict(self.best_mu_c_state)\n",
    "                    self.mu_t.load_state_dict(self.best_mu_t_state)\n",
    "                break\n",
    "            \n",
    "            # Break if used time allowed\n",
    "            elapsed_time = time.perf_counter() - start_time\n",
    "            if elapsed_time > total_time:\n",
    "                break\n",
    "\n",
    "        # If not early stopping or if early stopping happened on last epoch,\n",
    "        # potentially load the best model state if validation was used.\n",
    "        if self.val_size > 0 and self.best_mu_c_state and self.best_mu_t_state:\n",
    "             self.mu_c.load_state_dict(self.best_mu_c_state)\n",
    "             self.mu_t.load_state_dict(self.best_mu_t_state)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: pd.DataFrame, return_components: bool = False) -> np.ndarray | tuple:\n",
    "        \"\"\"\n",
    "        Predict Conditional Average Treatment Effect (CATE).\n",
    "\n",
    "        Args:\n",
    "            X (pd.DataFrame): Feature matrix for prediction.\n",
    "            return_components (bool, optional): If True, return tuple of\n",
    "                                                (cate, y_pred_c, y_pred_t).\n",
    "                                                Defaults to False.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray or tuple: Predicted CATE = mu_t(X) - mu_c(X)\n",
    "                                 (or tuple if return_components is True).\n",
    "        \"\"\"\n",
    "        if self.X_tensor is None: # Check if fit has been called\n",
    "            raise RuntimeError(\"Model has not been fitted yet. Call fit() first.\")\n",
    "\n",
    "        self.mu_c.eval()\n",
    "        self.mu_t.eval()\n",
    "\n",
    "        X = convert_pd_to_np(X)\n",
    "        X_np = self.scaler.transform(X).astype(np.float32) # Scale data\n",
    "        X_pred_tensor = torch.tensor(X_np, dtype=torch.float32).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            y_pred_c = self.mu_c(X_pred_tensor)\n",
    "            y_pred_t = self.mu_t(X_pred_tensor)\n",
    "\n",
    "        cate_pred = y_pred_t - y_pred_c\n",
    "\n",
    "        # Convert to numpy arrays\n",
    "        cate_pred_np = cate_pred.cpu().numpy()\n",
    "        if return_components:\n",
    "            y_pred_c_np = y_pred_c.cpu().numpy()\n",
    "            y_pred_t_np = y_pred_t.cpu().numpy()\n",
    "            return cate_pred_np, y_pred_c_np, y_pred_t_np\n",
    "        else:\n",
    "            return cate_pred_np\n",
    "\n",
    "    def estimate_ate(self, X: pd.DataFrame) -> float:\n",
    "        \"\"\"\n",
    "        Estimate the Average Treatment Effect (ATE).\n",
    "\n",
    "        Args:\n",
    "            X (pd.DataFrame): Feature matrix for ATE estimation.\n",
    "\n",
    "        Returns:\n",
    "            float: Estimated ATE.\n",
    "        \"\"\"\n",
    "        cate_pred = self.predict(X, return_components=False)\n",
    "        # Average the predictions\n",
    "        return float(np.mean(cate_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patsy import dmatrix\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "class LassoSplineLearner:\n",
    "    def __init__(self, df_spline=7, cv=5):\n",
    "        \"\"\"\n",
    "        LASSO model with natural spline and pairwise interactions.\n",
    "        \n",
    "        :param df_spline: Degrees of freedom for the natural spline.\n",
    "        :param cv: Number of cross-validation folds for LASSO.\n",
    "        \"\"\"\n",
    "        self.df_spline = df_spline\n",
    "        self.cv = cv\n",
    "        self.lasso = None  # Model will be assigned after fitting\n",
    "\n",
    "    def get_params(self):\n",
    "        return self.df_spline, self.cv\n",
    "    \n",
    "    def _transform_features(self, X):\n",
    "        \"\"\"Apply natural spline expansion and pairwise interactions.\"\"\"\n",
    "        df = pd.DataFrame(X, columns=[f\"X{i}\" for i in range(X.shape[1])])\n",
    "        # Create spline transformations for each feature individually\n",
    "        spline_terms = []\n",
    "        for i in range(X.shape[1]):\n",
    "            spline_terms.append(f\"bs(X{i}, df={self.df_spline}, include_intercept=False)\")\n",
    "        \n",
    "        formula = \" + \".join(spline_terms)  # Combine all spline transformations\n",
    "        spline_basis = dmatrix(formula, data=df, return_type='dataframe')\n",
    "\n",
    "        # Apply pairwise interactions\n",
    "        poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=True, )\n",
    "        return poly.fit_transform(spline_basis)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit LASSO on transformed features.\"\"\"\n",
    "        X_transformed = self._transform_features(X)\n",
    "        self.lasso = Lasso(random_state=123, ).fit(X_transformed, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict using trained LASSO model.\"\"\"\n",
    "        if self.lasso is None:\n",
    "            raise ValueError(\"Model is not trained. Call `.fit()` first.\")\n",
    "        X_transformed = self._transform_features(X)\n",
    "        return self.lasso.predict(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model, learner):\n",
    "    learner_dict = {\n",
    "        'S-Learner': BaseSRegressor(learner),\n",
    "        'T-Learner': BaseTRegressor(learner),\n",
    "        'X-Learner': BaseXRegressor(learner),\n",
    "        'RT-Learner': BaseRTRegressor(learner),\n",
    "        'P-Learner': BasePRegressor(learner),\n",
    "        'RP-Learner': BaseRPRegressor(learner)\n",
    "    }\n",
    "    return learner_dict[model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairnet_nn(input_dim, hidden_dims, epochs):\n",
    "    pairnet_nn = PairNetTorch(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dims=hidden_dims,\n",
    "        learning_rate=0.001,\n",
    "        weight_decay=0.0001,\n",
    "        epochs=epochs,\n",
    "        batch_size=200,\n",
    "        distance_threshold=np.inf, # Use max neighbours for all samples\n",
    "        num_neighbours=3,\n",
    "        val_size=0.1, # Use 10% of pairs for validation/early stopping\n",
    "        patience=10,\n",
    "        verbose=epochs+1, # No verbosity\n",
    "    )\n",
    "    return pairnet_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(n_list, p_list, s_list, m_list, learner_dict, num_iter,\n",
    "                    propensity_learner=None):\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "    for i in tqdm(range(num_iter)):\n",
    "\n",
    "        for n, p, s, m in product(n_list, p_list, s_list, m_list):\n",
    "            \n",
    "            # No limit on time if P-learner not run\n",
    "            pairnet_time=np.inf\n",
    "\n",
    "            # X, W, y, tau = generate_data_setup_a(n*2, p, s)\n",
    "\n",
    "            y, X, W, tau, _, _ = synthetic_data(mode=m, n=n*2, p=p, sigma=s)\n",
    "            X_train, X_test, W_train, _, y_train, _, _, tau_test = train_test_split(\n",
    "                X, W, y, tau, test_size=0.5, random_state=111)\n",
    "\n",
    "            if propensity_learner is not None:\n",
    "                em = clone(propensity_learner)\n",
    "                em.fit(X_train, W_train)\n",
    "                e_hat_train = cross_val_predict(em, X_train, W_train, method='predict_proba')[:, 1]\n",
    "                e_hat_test = em.predict_proba(X_test)[:, 1]\n",
    "\n",
    "            for learner in ['P-learner', 'PairNet']:\n",
    "\n",
    "                start_time = time.perf_counter()\n",
    "\n",
    "                if learner != 'PairNet':\n",
    "                    model = deepcopy(learner_dict[learner])\n",
    "                    model.fit(X=X_train, treatment=W_train, y=y_train, p=e_hat_train)\n",
    "                    hat_tau = model.predict(X_test, p=e_hat_test)\n",
    "                else:\n",
    "                    model = create_pairnet_nn(X_train.shape[1], (16,16), 1000)\n",
    "                    model.fit(X_train, W_train, y_train, total_time=pairnet_time)\n",
    "                    hat_tau = model.predict(X_test)\n",
    "\n",
    "                pehe = mean_squared_error(tau_test, hat_tau)\n",
    "\n",
    "                elapsed_time = time.perf_counter() - start_time\n",
    "\n",
    "                # If P-learner run, limit time to train PairNet\n",
    "                if learner == 'P-learner':\n",
    "                    pairnet_time = elapsed_time\n",
    "\n",
    "                result_list.append([n, p, s, m, learner, pehe, elapsed_time])  \n",
    "\n",
    "    cols = ['num_samples', 'num_features', 'sigma', 'sim_mode', 'learner', 'pehe', 'time']\n",
    "    df_res = pd.DataFrame(result_list, columns=cols)\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [02:23<05:47,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after epoch 11. Best Val Loss: 36.0211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [05:17<02:48,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after epoch 11. Best Val Loss: 33.3585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [08:08<00:00,  4.88s/it]\n"
     ]
    }
   ],
   "source": [
    "# Simulation params from Nie and Wager (2020)\n",
    "n_list = [1000]\n",
    "p_list = [10]\n",
    "s_list = [0, 1, 4]\n",
    "m_list = [1,2,3,4]\n",
    "num_iter = 100\n",
    "\n",
    "learner=RandomForestRegressor(max_depth=10)\n",
    "learner = MLPRegressor((16,16), max_iter=100, early_stopping=True, validation_fraction=0.1)\n",
    "#learner=LassoSplineLearner()\n",
    "#learner = XGBRegressor(max_depth=10)\n",
    "\n",
    "learner_dict = {\n",
    "    #'S-learner': BaseSRegressor(learner),\n",
    "    #'T-learner': BaseTRegressor(learner),\n",
    "    #'X-learner': BaseXRegressor(learner),\n",
    "    #'R-learner': BaseRRegressor(learner),\n",
    "    #'DR-learner': BaseDRRegressor(learner),\n",
    "    #'PDR-learner': BasePDRRegressor(learner),\n",
    "    #'RT-learner': BaseRTRegressor(learner=learner),\n",
    "    'P-learner': BasePRegressor(learner),\n",
    "    #'RP-learner': BaseRPRegressor(learner=learner),\n",
    "    'PairNet': ''\n",
    "}\n",
    "\n",
    "propensity_learner = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "\n",
    "df_res_nn_p = run_experiments(n_list, p_list, s_list, m_list, learner_dict, num_iter, propensity_learner=propensity_learner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_res_nn_p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Pivot table to restructure the dataframe\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df_pivot \u001b[38;5;241m=\u001b[39m \u001b[43mdf_res_nn_p\u001b[49m\u001b[38;5;241m.\u001b[39mpivot_table(\n\u001b[1;32m      3\u001b[0m     index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_samples\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_features\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigma\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msim_mode\u001b[39m\u001b[38;5;124m'\u001b[39m,],  \u001b[38;5;66;03m# Grouping columns\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearner\u001b[39m\u001b[38;5;124m\"\u001b[39m,          \u001b[38;5;66;03m# Learner categories become new columns\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     values\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpehe\u001b[39m\u001b[38;5;124m\"\u001b[39m],              \u001b[38;5;66;03m# MSE values\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     aggfunc\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msem\u001b[39m\u001b[38;5;124m'\u001b[39m]              \u001b[38;5;66;03m# Averaging the MSE values\u001b[39;00m\n\u001b[1;32m      7\u001b[0m )\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Rename columns if needed\u001b[39;00m\n\u001b[1;32m     10\u001b[0m df_pivot\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Remove the automatic column name\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_res_nn_p' is not defined"
     ]
    }
   ],
   "source": [
    "# Pivot table to restructure the dataframe\n",
    "df_pivot = df_res_nn_p.pivot_table(\n",
    "    index=['num_samples', 'num_features', 'sigma', 'sim_mode',],  # Grouping columns\n",
    "    columns=\"learner\",          # Learner categories become new columns\n",
    "    values=[\"pehe\"],              # MSE values\n",
    "    aggfunc=[\"mean\", 'sem']              # Averaging the MSE values\n",
    ").reset_index()\n",
    "\n",
    "# Rename columns if needed\n",
    "df_pivot.columns.name = None  # Remove the automatic column name\n",
    "\n",
    "# Function to apply bold formatting\n",
    "def highlight_min(s):\n",
    "    is_min = s == s.min()\n",
    "    return [\"font-weight: bold\" if v else \"\" for v in is_min]\n",
    "\n",
    "# Apply formatting to only the learner columns\n",
    "learner_columns = df_pivot.columns[4:]  # Excluding 'n', 'd', 'sigma'\n",
    "styled_df = df_pivot.sort_values(['sim_mode', 'num_features','sigma']).style.format(precision=3).apply(highlight_min, subset=learner_columns, axis=1)\n",
    "\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{lrrrrrrrr}\\n & num_samples & num_features & sigma & sim_mode & \\\\multicolumn{2}{r}{mean} & \\\\multicolumn{2}{r}{sem} \\\\\\\\\\n &  &  &  &  & \\\\multicolumn{2}{r}{pehe} & \\\\multicolumn{2}{r}{pehe} \\\\\\\\\\nlearner &  &  &  &  & P-learner & PairNet & P-learner & PairNet \\\\\\\\\\n0 & 1000 & 10 & 0 & 1 & 0.035 & 0.089 & \\\\font-weightbold 0.001 & 0.003 \\\\\\\\\\n4 & 1000 & 10 & 1 & 1 & 0.169 & 0.143 & \\\\font-weightbold 0.009 & 0.010 \\\\\\\\\\n8 & 1000 & 10 & 4 & 1 & 1.293 & 0.228 & 0.117 & \\\\font-weightbold 0.014 \\\\\\\\\\n1 & 1000 & 10 & 0 & 2 & 0.165 & 0.411 & \\\\font-weightbold 0.006 & 0.017 \\\\\\\\\\n5 & 1000 & 10 & 1 & 2 & 0.634 & 0.562 & \\\\font-weightbold 0.015 & 0.022 \\\\\\\\\\n9 & 1000 & 10 & 4 & 2 & 4.725 & 1.156 & 0.239 & \\\\font-weightbold 0.035 \\\\\\\\\\n2 & 1000 & 10 & 0 & 3 & 0.321 & 0.578 & 0.029 & \\\\font-weightbold 0.015 \\\\\\\\\\n6 & 1000 & 10 & 1 & 3 & 1.065 & 0.611 & 0.055 & \\\\font-weightbold 0.017 \\\\\\\\\\n10 & 1000 & 10 & 4 & 3 & 6.695 & 0.708 & 0.203 & \\\\font-weightbold 0.044 \\\\\\\\\\n3 & 1000 & 10 & 0 & 4 & 0.039 & 0.272 & \\\\font-weightbold 0.002 & 0.007 \\\\\\\\\\n7 & 1000 & 10 & 1 & 4 & 0.729 & 0.473 & 0.018 & \\\\font-weightbold 0.015 \\\\\\\\\\n11 & 1000 & 10 & 4 & 4 & 9.029 & 1.311 & 0.349 & \\\\font-weightbold 0.036 \\\\\\\\\\n\\\\end{tabular}\\n'"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "styled_df.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generation_descs = {\n",
    "    1: 'Setup 1',\n",
    "    2: 'Setup 2',\n",
    "    3: 'Setup 3',\n",
    "    4: 'Setup 4'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, m in zip(range(4), m_list):\n",
    "    sns.boxplot(x='learner', y='pehe', data=df_res_nn.loc[(df_res_nn['sim_mode'] == m) & (df_res_nn['sigma'] == 1) & \n",
    "                                                          (df_res_nn['learner'] != 'RT-Learner')], linewidth=1, showfliers=False, \n",
    "                                                          ax=axs[i], palette=palette)\n",
    "    axs[i].title.set_text(data_generation_descs[m] + r' (RF)')\n",
    "    axs[i].set_ylabel('time (s)')\n",
    "    axs[i].set_xlabel('')\n",
    "    axs[i].tick_params(labelsize=12)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "axs = axs.ravel()\n",
    "\n",
    "for i, m in zip(range(2), m_list):\n",
    "    sns.boxplot(x='learner', y='pehe', data=df_res_nn.loc[(df_res_nn['sim_mode'] == m) & (df_res_nn['sigma'] == 4) & \n",
    "                                                          (df_res_nn['learner'] != 'RT-Learner')], linewidth=1, showfliers=False, \n",
    "                                                          ax=axs[i], palette=palette)\n",
    "    axs[i].title.set_text(data_generation_descs[m] + r' (NN, $\\sigma=4$)')\n",
    "    axs[i].set_ylabel('PEHE')\n",
    "    axs[i].set_xlabel('')\n",
    "    axs[i].tick_params(labelsize=12)\n",
    "plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
